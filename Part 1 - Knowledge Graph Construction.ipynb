{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed5319f2-b647-4bcc-90b2-8f748ed39eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import gzip\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "from datetime import date\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import Tensor\n",
    "\n",
    "sns.set(style='white', context='poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312d8d-ed3d-4f0d-811f-58d5c810a8c1",
   "metadata": {},
   "source": [
    "Part 1: Knowledge Graph Construction\n",
    "====================================\n",
    "\n",
    "In this section of the course, we will cover _knowledge graph construction_ or how to construct knowledge graphs from both _natural networks_ and _structural networks_. In the lecture I described _knowledge graph construction_ as the process of building a knowledge graph from raw data using ETL, data transformations or Natural Language Processing (NLP).\n",
    "\n",
    "There are two main types of networks in common use: simple and heterogeneous networks. We're going to start out building a simple network where nodes are _academic papers_ and edges are _citations between papers_.\n",
    "\n",
    "<center><img src=\"images/Graphs-vs-Heterogeneous-Graphs-2000px.png\" width=\"1000px\" /></center>\n",
    "\n",
    "There are two categories of data from which we can build networks: _natural networks_ and _structural networks_. We can also transform _existing networks_ that are already formatted and easy to work with.\n",
    "\n",
    "<center><img src=\"images/ETL-in-Natural-and-Structural-Graphs.jpg\" width=\"860px\" /></center>\n",
    "\n",
    "Given time, we'll be building both _simple_ and _heterogeneous networks_ from both _natural_ and _structural graphs_. We'll start with the former.\n",
    "\n",
    "# Section Textbook\n",
    "\n",
    "An excellent resource for the first two parts of this course, **Knowledge Graph Construction** and **Network Science** is the [Network Science (CC4063 / CC4095)](https://www.dcc.fc.up.pt/~pribeiro/aulas/ns2122/) class taught by [Pedro Ribeiro](https://www.dcc.fc.up.pt/~pribeiro/) at the [Center for Research in Advanced Computing Systems](https://cracs.fc.up.pt/), part of the [Computer Science Department](https://www.dcc.fc.up.pt/site/) of the [University of Porto](https://www.up.pt/portal/en/).\n",
    "\n",
    "We will be using [Section 10: Network Construction](https://www.dcc.fc.up.pt/~pribeiro/aulas/ns2122/handouts.html#construction) during this part of the course, and specifically the slides for that section: [Network Construction (selected slides from J. Leskovec and L. Lacasa)](https://www.dcc.fc.up.pt/~pribeiro/aulas/ns2122/10_netconstruction.pdf).\n",
    "\n",
    "# Setting up Graphistry\n",
    "\n",
    "First let's setup a network visualization tool to help us evaluate what we are building. Throughout this part of the course we will be using `pygraphistry` and [Graphistry Hub](https://hub.graphistry.com/) [https://hub.graphistry.com/](https://hub.graphistry.com/) to visualize networks. Both are free for personal use and are powerful for visualizing networks large and small.\n",
    "\n",
    "You can [signup](https://hub.graphistry.com/accounts/signup/) for a Graphistry account at [https://hub.graphistry.com/accounts/signup/](https://hub.graphistry.com/accounts/signup/). <b>You should use a username/password/email to get the required credentials</b>, although after that you can login with your Github or Google account.\n",
    "\n",
    "<center><img src=\"images/graphistry_hub_registration.png\" /></center>\n",
    "\n",
    "Retain and use your credentials in the login form and in the environment variables in the next cell below. You should set the `GRAPHISTRY_USERNAME` and `GRAPHISTRY_PASSWORD` variables in the `env/graphistry.env` file, and then restart this docker container to pickup the new values.\n",
    "\n",
    "<center><img src=\"images/graphistry_hub_homepage.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94962741-ff18-417f-a218-52e6a61f5a0e",
   "metadata": {},
   "source": [
    "# ETL for a Simple, Natural Graph: High-energy Physics Theory Citation Network\n",
    "\n",
    "We are going to start out by building a knowledge graph from an existing edge list and then add properties to it. We'll be using the [High-energy physics theory citation network](https://snap.stanford.edu/data/cit-HepTh.html) from [Stanford SNAP](https://snap.stanford.edu/index.html). SNAP has many large network datasets available in the [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/).\n",
    "\n",
    "The dataset includes the following files, which we will combine:\n",
    "\n",
    "* [Citation graph edge list](https://snap.stanford.edu/data/cit-HepTh.txt.gz) contains node ID pairs. Node IDs are standard paper identifiers. This will build the core structure of our network.\n",
    "* [Paper metadata](cit-HepTh-abstracts.tar.gz) including abstracts. This will add propertis to our network.\n",
    "* [Publishing dates on arXiv](https://snap.stanford.edu/data/cit-HepTh-dates.txt.gz) will make our citation network a temporal [Directed-Acyclic-Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) since one paper can't cite another before it is written and there are no reciprocal edges. While we don't focus on this, it does affect our analysis.\n",
    "\n",
    "## Dataset Citation\n",
    "\n",
    "```\n",
    "Paper: hep-th/0002031\n",
    "From: Maulik K. Parikh \n",
    "Date: Fri, 4 Feb 2000 17:04:51 GMT   (10kb)\n",
    "\n",
    "Title: Confinement and the AdS/CFT Correspondence\n",
    "Authors: D. S. Berman and Maulik K. Parikh\n",
    "Comments: 12 pages, 1 figure, RevTeX\n",
    "Report-no: SPIN-1999/25, UG-1999/42\n",
    "Journal-ref: Phys.Lett. B483 (2000) 271-276\n",
    "\\\\\n",
    "  We study the thermodynamics of the confined and unconfined phases of\n",
    "superconformal Yang-Mills in finite volume and at large N using the AdS/CFT\n",
    "correspondence. We discuss the necessary conditions for a smooth phase\n",
    "crossover and obtain an N-dependent curve for the phase boundary.\n",
    "\\\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c191a7-0372-4723-9909-cefd2afc61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variable setup\n",
    "GRAPHISTRY_USERNAME = os.getenv(\"GRAPHISTRY_USERNAME\")\n",
    "GRAPHISTRY_PASSWORD = os.getenv(\"GRAPHISTRY_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e92082-faad-40a2-836e-ca7f98c5f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphistry.register(\n",
    "    api=3,\n",
    "    username=GRAPHISTRY_USERNAME,\n",
    "    password=GRAPHISTRY_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09972cd9-b909-445f-8b78-94d1978b4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Graphistry\n",
    "GRAPHISTRY_PARAMS = {\n",
    "    \"play\": 600,\n",
    "    \"pointOpacity\": 0.7,\n",
    "    \"edgeOpacity\": 0.3,\n",
    "    \"edgeCurvature\": 0.3,\n",
    "    \"showArrows\": True,\n",
    "    \"gravity\": 0.5,\n",
    "}\n",
    "FAVICON_URL = \"https://graphlet.ai/assets/icons/favicon.ico\"\n",
    "LOGO = {\"url\": \"https://graphlet.ai/assets/Branding/Graphlet%20AI.svg\", \"dimensions\": {\"maxWidth\": 100, \"maxHeight\": 100}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3cf16-524f-49a0-9865-eb5924e357d1",
   "metadata": {},
   "source": [
    "## `NetworkX` on PyPi is `networkx` in code is `nx`.\n",
    "\n",
    "The convention we used above is to load NetworkX via `import networkx as nx` so we can use the shorthand `nx` to call its classes and algorithms.\n",
    "\n",
    "## Numeric Node IDs\n",
    "\n",
    "What follows is a demonstration of _knowledge graph construction_, which we covered in the lecture. A node/edge list was provided, but the IDs are not sequential... which a network sampling tool I hope to use called [littleballoffur](https://github.com/benedekrozemberczki/littleballoffur) requires. In fact many graph libraries require sequential IDs. We must transform the graph IDs, create a mapping back and forth and annotate the nodes with properties for both IDs.\n",
    "\n",
    "## Build a Directional Graph (nx.DiGraph) from a CSV\n",
    "\n",
    "The edge list is a `#` commented, space-delimited CSV. We will parse it, assign sequential IDs and build a [`nx.DiGraph`](https://networkx.org/documentation/stable/reference/classes/digraph.html).\n",
    "\n",
    "### Download the Citation Edge List\n",
    "\n",
    "First, we download the edge list and build the structure of the network: `(paper)-cited->(paper)`. Note that we cache the edge list so you can edit the code without having to re-download the data.\n",
    "\n",
    "The edge list is located at [https://snap.stanford.edu/data/cit-HepTh.txt.gz](https://snap.stanford.edu/data/cit-HepTh.txt.gz) and is stored in `data/cit-HepTh.txt.gz`. We will read the file in its compressed state via the `gzip` builtin library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4b88f4-deaf-444a-b90f-10bd9b7dad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing citation graph edge file data/cit-HepTh.txt.gz\n"
     ]
    }
   ],
   "source": [
    "# Download and load edges (citations) from `cit-HepTh.txt.gz`\n",
    "edge_path = \"data/cit-HepTh.txt.gz\"\n",
    "gzip_content = None\n",
    "\n",
    "if os.path.exists(edge_path):\n",
    "    print(f\"Using existing citation graph edge file {edge_path}\")\n",
    "    gzip_content = open(edge_path, \"rb\")\n",
    "else:\n",
    "    print(\"Fetching citation graph edge file ...\")\n",
    "    response = requests.get(f\"https://snap.stanford.edu/{edge_path}\")\n",
    "    gzip_content = io.BytesIO(response.content)\n",
    "\n",
    "    print(\"Writing edge list to file {edge_path}\")\n",
    "    with open(edge_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "        print(f\"Wrote downloaded edge file to {edge_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1ba635-1606-4e15-9b2f-795b79e44753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Directed graph (each unordered pair of nodes is saved once): Cit-HepTh.txt \n",
      "# Paper citation network of Arxiv High Energy Physics Theory category\n",
      "# Nodes: 27770 Edges: 352807\n",
      "# FromNodeId\tToNodeId\n",
      "1001\t9304045\n",
      "1001\t9308122\n",
      "1001\t9309097\n",
      "1001\t9311042\n",
      "1001\t9401139\n",
      "1001\t9404151\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Check the top 10 lines of our gzip text file\n",
    "!zcat data/cit-HepTh.txt.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88106b1c-c9a1-4ebe-82e2-a54d2b31df9e",
   "metadata": {},
   "source": [
    "### Graph and Identifier Setup\n",
    "\n",
    "We create directional a [`nx.DiGraph`](https://networkx.org/documentation/stable/reference/classes/digraph.html) because citations are inherently directional: from citer to cited. Note that whether we model them this way or not, citation graphs are temporal networks. The citing paper's publishing date must fall after cited paper's publishing date. We'll load publishing dates below.\n",
    "\n",
    "We need to setup `file_to_net` and `net_to_file` dictionaries to map back and forth between the file format's identifiers and or own sequential identifiers we'll be assigning starting with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b66727-06b4-4c72-b02a-1caf2a66242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a directed graph\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71c3f84c-c441-46f1-988b-7bca8c561a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create sequential IDs starting from 0 for littleballoffur and DGL\n",
    "file_to_net: Dict[int, int] = {}\n",
    "net_to_file: Dict[int, int] = {}\n",
    "current_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ae24c-b54d-4a5a-b286-c5f0288eaab4",
   "metadata": {},
   "source": [
    "### From Text to Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cd66174-f00d-448d-be65-b68787ea7adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network structure ...\n",
      "Network built! It contains 27,770 nodes and 352,807 edges.\n"
     ]
    }
   ],
   "source": [
    "# Decompress the gzip content and build the edge list for our network\n",
    "print(\"Building network structure ...\")\n",
    "\n",
    "# Note we reuse the `gzip_content` variable from the download cell. This is a weird way to do it :)\n",
    "with gzip.GzipFile(fileobj=gzip_content) as f:\n",
    "\n",
    "    # Iterate through the lines, using the `line_number` as an `edge_id` below.\n",
    "    # They won't quite start at 0 owing to comments, but that's ok in the case of edges.\n",
    "    for line_number, line in enumerate(f):\n",
    "        line = line.decode(\"utf-8\")\n",
    "\n",
    "        # Ignore comment lines that start with '#'\n",
    "        if not line.startswith(\"#\"):\n",
    "            # Source (citing), desstination (cited) papers\n",
    "            citing_key, cited_key = line.strip().split(\"\\t\")\n",
    "\n",
    "            # The edge list makes the paper ID an int, stripping 0001001 to 1001, for example\n",
    "            citing_key, cited_key = int(citing_key), int(cited_key)\n",
    "\n",
    "            # If the either of the paper IDs don't exist, make one\n",
    "            for key in [citing_key, cited_key]:\n",
    "                if key not in file_to_net:\n",
    "                    # Build up an index that maps back and forth\n",
    "                    file_to_net[key] = current_idx\n",
    "                    net_to_file[current_idx] = key\n",
    "\n",
    "                    # Bump the current ID\n",
    "                    current_idx += 1\n",
    "\n",
    "            # print(f\"Citing key: {citing_key}, Cited key: {cited_key}\")\n",
    "            # print(f\"Mapped key: {file_to_net[citing_key]}, Mapped key: {file_to_net[cited_key]}\")\n",
    "\n",
    "            G.add_edge(file_to_net[citing_key], file_to_net[cited_key], edge_id=line_number)\n",
    "\n",
    "            # Conditionally set the keys on the nodes\n",
    "            G.nodes[file_to_net[citing_key]][\"file_id\"] = citing_key\n",
    "            G.nodes[file_to_net[citing_key]][\"sequential_id\"] = file_to_net[citing_key]\n",
    "\n",
    "            G.nodes[file_to_net[cited_key]][\"file_id\"] = cited_key\n",
    "            G.nodes[file_to_net[cited_key]][\"sequential_id\"] = file_to_net[cited_key]\n",
    "\n",
    "print(f\"Network built! It contains {G.number_of_nodes():,} nodes and {G.number_of_edges():,} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5d993-5545-4886-966a-e622d2409215",
   "metadata": {},
   "source": [
    "## Node Properties from Abstract Metadata\n",
    "\n",
    "In addition to the edge list, SNAP provides the paper's essential metadata in another file, which we will load to provide node properties and text embeddings for citation graph.\n",
    "\n",
    "We are going to perform the following steps:\n",
    "\n",
    "1) Download and cache the metadata to `data/cit-HepTh-abstracts.tar.gz`. Note that 1 file corresponds to one paper node's metadata.\n",
    "2) Process the tarball file where one file corresponds to one node ID in the original file. See why we made or mappings `file_to_net` and `net_to_file`?\n",
    "3) Assign node properties by parsing the fields of the record using traditional information extraction with regular expressions.\n",
    "4) Use a sentence transformer paraphrase model to summarize the entire textual record and enable node comparison for journal label creation.\n",
    "\n",
    "### Downloading the Abstract Metadata\n",
    "\n",
    "Another file containing node metadata, including the abstracts, for about 90% of nodes in this network is provided at [https://snap.stanford.edu/data/cit-HepTh-abstracts.tar.gz](https://snap.stanford.edu/data/cit-HepTh-abstracts.tar.gz), which we will save to `data/cit-HepTh-abstracts.tar.gz`. This code works just like the edge list download code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4609227a-1af3-41fd-9921-7715c11d9685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching paper abstracts ...\n",
      "Using existing paper abstracts file data/cit-HepTh-abstracts.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Download the abstracts from `cit-HepTh-abstracts.tar.gz`\n",
    "print(\"Fetching paper abstracts ...\")\n",
    "abstract_path = \"data/cit-HepTh-abstracts.tar.gz\"\n",
    "abstract_gzip_content = None\n",
    "\n",
    "if os.path.exists(abstract_path):\n",
    "    print(f\"Using existing paper abstracts file {abstract_path}\")\n",
    "    with open(abstract_path, \"rb\") as f:\n",
    "        abstract_gzip_content = io.BytesIO(f.read())\n",
    "else:\n",
    "    print(\"Downloading paper abbstracts ...\")\n",
    "    abstract_response = requests.get(f\"https://snap.stanford.edu/{abstract_path}\")\n",
    "    abstract_gzip_content = io.BytesIO(abstract_response.content)\n",
    "\n",
    "    print(f\"Downloading abstract file to {abstract_path}\")\n",
    "    with open(abstract_path, \"wb\") as f:\n",
    "        f.write(abstract_response.content)\n",
    "        print(f\"Wrote downloaded abstract file to {abstract_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee4892-b011-4b3b-bb18-78633a297a3b",
   "metadata": {},
   "source": [
    "### Manually Parsing Node Metadata\n",
    "\n",
    "As a first pass let's use regular expressions in the Python `re` builtin library to extract each paper's fields so we can assign them as properties to our `nx.DiGraph` nodes.\n",
    "\n",
    "Here is what a couple of **test documents** look like. This is corresponds to two files in our abstract tarball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce09eff3-3189-45c5-b139-3d346bf97e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "\"\"\"------------------------------------------------------------------------------\n",
    "\\\\\n",
    "Paper: hep-th/9612115\n",
    "From: Asato Tsuchiya <tsuchiya@theory.kek.jp>\n",
    "Date: Wed, 11 Dec 1996 17:38:56 +0900   (20kb)\n",
    "Date (revised): Tue, 31 Dec 1996 01:06:34 +0900\n",
    "\n",
    "Title: A Large-N Reduced Model as Superstring\n",
    "Authors: N. Ishibashi, H. Kawai, Y. Kitazawa and A. Tsuchiya\n",
    "Comments: 29 pages, Latex, a footnote and references added, eq.(3.52)\n",
    "corrected, minor corrections\n",
    "Report-no: KEK-TH-503, TIT/HEP-357\n",
    "Journal-ref: Nucl.Phys. B498 (1997) 467-491\n",
    "\\\\\n",
    "A matrix model which has the manifest ten-dimensional N=2 super Poincare\n",
    "invariance is proposed. Interactions between BPS-saturated states are analyzed\n",
    "to show that massless spectrum is the same as that of type IIB string theory.\n",
    "It is conjectured that the large-N reduced model of ten-dimensional super\n",
    "Yang-Mills theory can be regarded as a constructive definition of this model\n",
    "and therefore is equivalent to superstring theory.\n",
    "\\\\\n",
    "\"\"\",\n",
    "    \"\"\"------------------------------------------------------------------------------\n",
    "\\\\\n",
    "Paper: hep-th/9711029\n",
    "From: John Schwarz <jhs@theory.caltech.edu>\n",
    "Date: Wed, 5 Nov 1997 17:30:55 GMT   (20kb)\n",
    "Date (revised v2): Thu, 6 Nov 1997 23:52:45 GMT   (21kb)\n",
    "\n",
    "Title: The Status of String Theory\n",
    "Author: John H. Schwarz\n",
    "Comments: 16 pages, latex, two figures; minor corrections, references added\n",
    "Report-no: CALT-68-2140\n",
    "\\\\\n",
    "There have been many remarkable developments in our understanding of\n",
    "superstring theory in the past few years, a period that has been described as\n",
    "``the second superstring revolution.'' Several of them are discussed here. The\n",
    "presentation is intended primarily for the benefit of nonexperts.\n",
    "\\\\\n",
    "\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f48a8b-95b3-404e-8658-7c9fd4002acd",
   "metadata": {},
   "source": [
    "### Structured Information Extraction with a Regex Helper\n",
    "\n",
    "Our extract function was created through trial and error using the [Pythex Regex Editor](https://pythex.org/). Paste the test documents where it says `Your test data` and try a couple of the patterns such as `r\"\"` above that where it says `Your regular expression`. It will show you where the patterns match in your data. A new section displays the matches within the text and a window on the right shows the text your regular expression will return via the list the `match.groups()` command returns.\n",
    "\n",
    "A few cycles of this and we have a clean extraction. In practice, I used more test records than this, which I've spared you in the interest of time :) Regular expressions are difficult to learn, but there are resources and **ChatGPT-4 is quite capable at writing regex!** It wrote many of the ones below.\n",
    "\n",
    "<center><img src=\"images/Pythex-Regex-Helper.png\" width=\"1000px\" /></center>\n",
    "\n",
    "I used Pythex to help write the `extract_paper_info(record)` method below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b66d7e1-9e7a-4f51-adc2-7d26538b5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_info(record):\n",
    "    \"\"\"Extract structured information from the text of academic paper text records using regular expressions.\n",
    "\n",
    "    Note: I was written wholly or in part by ChatGPT4 on May 23, 2023.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary to hold the information\n",
    "    info = {}\n",
    "\n",
    "    # Match \"Paper\" field\n",
    "    paper_match = re.search(r\"Paper:\\s*(.*)\", record)\n",
    "    if paper_match:\n",
    "        info[\"Paper\"] = paper_match.group(1)\n",
    "\n",
    "    # # Match \"From\" field\n",
    "    # from_match = re.search(r\"From:\\s*(.*)\", record)\n",
    "    # if from_match:\n",
    "    #     info['From'] = from_match.group(1)\n",
    "\n",
    "    # Match \"From\" field\n",
    "    from_match = re.search(r\"From:\\s*([^<]*)<\", record)\n",
    "    if from_match:\n",
    "        info[\"From\"] = from_match.group(1).strip()\n",
    "\n",
    "    # Match \"Date\" field\n",
    "    date_match = re.search(r\"Date:\\s*(.*)(\\s*)(\\(\\d+kb\\))\", record)\n",
    "    if date_match:\n",
    "        info[\"Date\"] = date_match.group(1).strip()\n",
    "\n",
    "    # Match \"Title\" field\n",
    "    title_match = re.search(r\"Title:\\s*(.*)\", record)\n",
    "    if title_match:\n",
    "        info[\"Title\"] = title_match.group(1)\n",
    "\n",
    "    # Match \"Authors\" field\n",
    "    authors_match = re.search(r\"Authors:\\s*(.*)\", record)\n",
    "    if authors_match:\n",
    "        info[\"Authors\"] = authors_match.group(1)\n",
    "\n",
    "    # Match \"Comments\" field\n",
    "    comments_match = re.search(r\"Comments:\\s*(.*)\", record)\n",
    "    if comments_match:\n",
    "        info[\"Comments\"] = comments_match.group(1)\n",
    "\n",
    "    # Match \"Report-no\" field\n",
    "    report_no_match = re.search(r\"Report-no:\\s*(.*)\", record)\n",
    "    if report_no_match:\n",
    "        info[\"Report-no\"] = report_no_match.group(1)\n",
    "\n",
    "    # Match \"Journal-ref\" field\n",
    "    journal_ref_match = re.search(r\"Journal-ref:\\s*(.*)\", record)\n",
    "    if journal_ref_match:\n",
    "        info[\"Journal-ref\"] = journal_ref_match.group(1)\n",
    "\n",
    "    # Extract \"Abstract\" field\n",
    "    abstract_pattern = r\"Journal-ref:[^\\\\\\\\]*\\\\\\\\[\\n\\s]*(.*?)(?=\\\\\\\\)\"\n",
    "    abstract_match = re.search(abstract_pattern, record, re.DOTALL)\n",
    "    if abstract_match:\n",
    "        abstract = abstract_match.group(1)\n",
    "        abstract = abstract.replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "        info[\"Abstract\"] = abstract.strip()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f0c15-5080-4875-9c9a-9312ee9e5ab6",
   "metadata": {},
   "source": [
    "### Testing Our Information Extraction\n",
    "\n",
    "To develop the above I created the unit tests below. Inspect the values so you agree they work :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e92f08f8-aa75-44a7-8e9c-b941b7bf0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "(doc1, doc2) = docs\n",
    "\n",
    "paper_info = extract_paper_info(doc1)\n",
    "# Get the paper ID part of the \"Paper\" field\n",
    "paper_id = int(paper_info.get(\"Paper\", \"\").split(\"/\")[-1])\n",
    "assert paper_info[\"Paper\"] == \"hep-th/9612115\"\n",
    "assert paper_id == 9612115\n",
    "\n",
    "paper_info = extract_paper_info(doc2)\n",
    "# Get the paper ID part of the \"Paper\" field\n",
    "paper_id = int(paper_info.get(\"Paper\", \"\").split(\"/\")[-1])\n",
    "assert paper_info[\"Paper\"] == \"hep-th/9711029\"\n",
    "assert paper_id == 9711029"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1786f68-848a-442a-9e96-ccd70debf27a",
   "metadata": {},
   "source": [
    "### Setting Node Properties\n",
    "\n",
    "With our information extraction function tested, we are ready to loop through the abstract metadata tarball's files `G.nodes()` and assign the extract function's fields as node fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a18b0860-2b80-4903-9d5b-1bc7c557d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added metadata to 27,770 nodes, 1,785 were unknown.\n"
     ]
    }
   ],
   "source": [
    "hit_count, miss_count, matches = 0, 0, 0\n",
    "all_abstracts: List[str] = []\n",
    "abstracts: Dict[int, str] = {}\n",
    "paper_ids: List[int] = []\n",
    "# Decompress the gzip content, then work through the abstract files in the tarball\n",
    "with gzip.GzipFile(fileobj=abstract_gzip_content) as f:\n",
    "    with tarfile.open(fileobj=f, mode=\"r|\") as tar:\n",
    "        for member in tar:\n",
    "            abstract_file = tar.extractfile(member)\n",
    "            if abstract_file:\n",
    "                content = abstract_file.read().decode(\"utf-8\")\n",
    "\n",
    "                paper_id = int(os.path.basename(member.name).split(\".\")[0])\n",
    "\n",
    "                # We can also parse and use those values directly or embed field-wise\n",
    "                paper_info = extract_paper_info(content)\n",
    "                if paper_info:\n",
    "                    abstract_paper_id = paper_info.get(\"Paper\", \"\").split(\"/\")[-1]\n",
    "                    if paper_id != int(abstract_paper_id):\n",
    "                        matches += 1\n",
    "                        print(f\"Paper ID {paper_id} != {abstract_paper_id}\")\n",
    "\n",
    "                    # Get the paper ID part of the \"Paper\" field\n",
    "                    if paper_id in file_to_net and file_to_net[paper_id] in G:\n",
    "                        for field, value in paper_info.items():\n",
    "                            G.nodes[file_to_net[paper_id]][field] = value\n",
    "\n",
    "                        abstracts[paper_id] = content\n",
    "                        all_abstracts.append(content)\n",
    "                        paper_ids.append(paper_id)\n",
    "\n",
    "                        hit_count += 1\n",
    "\n",
    "                    else:\n",
    "                        # Add isolated nodes if paper_id isn't in G\n",
    "                        miss_count += 1\n",
    "                        # We could do this for some use cases to create isolated nodes. Not all graphs are connected. See Part 2, Network Science.\n",
    "                        # G.add_node(file_to_net[paper_id], **paper_info)\n",
    "\n",
    "# Now `G` is a property graph representing the \"High-energy physics theory citation network\" dataset\n",
    "print(f\"Added metadata to {hit_count:,} nodes, {miss_count:,} were unknown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7767a17-0955-4a8f-a34e-9996fcb54b90",
   "metadata": {},
   "source": [
    "## Temporal Networks\n",
    "\n",
    "Our citation graph is a temporal network. Temporal networks have a determined sequence in which nodes are added to the graph - just as real networks evolve. Network science and graph machine learning for temporal networks that don't take time into account can result in incorrect analyses and inaccurate machine learning inference.\n",
    "\n",
    "<center><img src=\"images/Temporal-vs-static-networks-A-The-sequence-of-contacts-among-three-nodes-capturing_W640.jpg\" width=\"800px\" /></center>\n",
    "<center>Image source: <a href=\"https://www.researchgate.net/publication/305492361_The_fundamental_advantages_of_temporal_networks\">The fundamental advantages of temporal networks, Li et al., 2016</a></center>\n",
    "\n",
    "### Downloading Publishing Dates\n",
    "\n",
    "The timestamps are available at [https://snap.stanford.edu/data/cit-HepTh-dates.txt.gz](https://snap.stanford.edu/data/cit-HepTh-dates.txt.gz) and are downloaded to `data/cit-HepTh-dates.txt.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d35f49a5-d300-4c10-8cef-ccbd664257fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing paper dates file data/cit-HepTh-dates.txt.gz\n"
     ]
    }
   ],
   "source": [
    "# Download and load edges (citations) from `cit-HepTh.txt.gz`\n",
    "dates_path = \"data/cit-HepTh-dates.txt.gz\"\n",
    "date_gzip_content = None\n",
    "\n",
    "if os.path.exists(dates_path):\n",
    "    print(f\"Using existing paper dates file {dates_path}\")\n",
    "    date_gzip_content = open(dates_path, \"rb\")\n",
    "else:\n",
    "    print(\"Downloading paper publishing dates ...\")\n",
    "    date_response = requests.get(f\"https://snap.stanford.edu/{dates_path}\")\n",
    "    date_gzip_content = io.BytesIO(date_response.content)\n",
    "\n",
    "    with open(dates_path, \"wb\") as f:\n",
    "        f.write(date_response.content)\n",
    "        print(\"Wrote downloaded publishing dates file to {dates_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc8390-c714-4c75-b702-5f3c243e1d0d",
   "metadata": {},
   "source": [
    "### Adding a Temporal Property\n",
    "\n",
    "Publishing dates go under the `Published` node property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acaca8e5-e0c1-4fbc-ba9a-a514218acccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding publising dates ...\n"
     ]
    }
   ],
   "source": [
    "# Decompress the gzip content and add a \"published\" date property to our nodes\n",
    "print(\"Adding publising dates ...\")\n",
    "with gzip.GzipFile(fileobj=date_gzip_content) as f:\n",
    "    for line in f:\n",
    "        line = line.decode(\"utf-8\")\n",
    "        # Ignore lines that start with '#'\n",
    "        if not line.startswith(\"#\"):\n",
    "            paper_id, iso_date = line.strip().split(\"\\t\")\n",
    "\n",
    "            # The edge list makes the paper ID an int, stripping 0001001 to 1001, for example\n",
    "            paper_id = int(paper_id)\n",
    "\n",
    "            if paper_id in file_to_net and file_to_net[paper_id] in G:\n",
    "                # Add a UTC timestamp for the data\n",
    "                G.nodes[file_to_net[paper_id]][\"Published\"] = calendar.timegm(\n",
    "                    date.fromisoformat(iso_date).timetuple()\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a45ded-092d-49e7-bcbd-55018997b7e7",
   "metadata": {},
   "source": [
    "### Test our Network Build\n",
    "\n",
    "Let's make sure everything built as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2a6d03a-4bbe-4997-b3fd-6ee1f728c927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"file_id\": 1001,\n",
      "    \"sequential_id\": 0,\n",
      "    \"Paper\": \"hep-th/0001001\",\n",
      "    \"From\": \"Paul S. Aspinwall\",\n",
      "    \"Date\": \"Sat, 1 Jan 2000 00:02:31 GMT\",\n",
      "    \"Title\": \"Compactification, Geometry and Duality: N=2\",\n",
      "    \"Authors\": \"Paul S. Aspinwall\",\n",
      "    \"Comments\": \"82 pages, 8 figures, LaTeX2e, TASI99, refs added and some typos fixed\",\n",
      "    \"Report-no\": \"DUKE-CGTP-00-01\",\n",
      "    \"Published\": 946684800\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# What is the first node?\n",
    "test_node = G.nodes[0]\n",
    "\n",
    "assert test_node[\"sequential_id\"] == 0\n",
    "assert test_node[\"file_id\"] == 1001\n",
    "\n",
    "print(json.dumps(test_node, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5228d39-a3d1-40ef-ab76-f1bf99b79c37",
   "metadata": {},
   "source": [
    "## Abstract Embeddings\n",
    "\n",
    "In addition to parsing the data, we will embed the entire record. First we create a utility to embed string columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0043881c-c4d7-4357-b284-7e65ffb2063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9ce41570c24564a6b761e17622d76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5431c3cefd11435994f2117abadad6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0696cbd6295e411c8564143de6d12f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea1f6b090a94182833b1ee1160f35f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486f3168b2b64e66ade35b3c53a2f235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625f711e3b904a54b1345bd58bb04876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96949fb6dc148db9c4184155db07f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c350fc544606463dbd1d9ab9fbc08b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a20255cb624b3284f9a941ba578602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b767197ce7df419fa96be509667c1ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d37ea67d66b407cbabb7a67d63db8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda6196c5e6b4635af102b722852133d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e1348a79ce4a08acab0cf3e6b0283a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052afcd5225944fdbbdb2dad741af769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fa37dfea-c8da-429d-83df-011c3fbc755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01bb1116-6b21-45f7-94f2-49fe6af97658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_paper_info(\n",
    "    records: Union[str, List[str]], convert_to_tensor=True\n",
    ") -> Union[np.ndarray, Tensor]:\n",
    "    if records and isinstance(records, str):\n",
    "        records = [records]\n",
    "    return paraphrase_model.encode(records, convert_to_tensor=convert_to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a38e4d-40f6-4484-be82-743f496cfdf8",
   "metadata": {},
   "source": [
    "Then we embed all the nodes' metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0734266-b939-4438-8711-f675bfa93479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the abstracts for GNN features. Embedding is a generic approach for retrieval as well.\n",
    "# Note: NetworkX can't save lists in GEXF format, so we'll JSONize the list & save the embeddings separately.\n",
    "embedded_abstracts: np.ndarray = None\n",
    "if os.path.exists(\"data/embedded_abstracts.npy\"):\n",
    "    embedded_abstracts = np.load(\"data/embedded_abstracts.npy\")\n",
    "else:\n",
    "    embedded_abstracts = embed_paper_info(all_abstracts, convert_to_tensor=False)\n",
    "    np.save(\"data/embedded_abstracts.npy\", embedded_abstracts)\n",
    "\n",
    "node_embedding_dict: Dict[int, List[float]] = {}\n",
    "if os.path.exists(\"data/node_embedding_dict.json.gz\"):\n",
    "    node_embedding_dict = json.load(\n",
    "        gzip.GzipFile(\"data/node_embedding_dict.json.gz\", \"r\"),\n",
    "        # encoding=\"utf-8\",\n",
    "    )\n",
    "else:\n",
    "    for paper_id, emb in zip(paper_ids, embedded_abstracts):\n",
    "        assert emb.shape == (384,)\n",
    "\n",
    "        # Gephi assumes a list of floats is a time series, so we need to convert to a string\n",
    "        emb_list = emb.tolist()\n",
    "        G.nodes[file_to_net[paper_id]][\"Embedding-JSON\"] = json.dumps(emb_list)\n",
    "\n",
    "        node_embedding_dict[paper_id] = emb_list\n",
    "\n",
    "# Write the mapping from paper ID to embedding to JSON.\n",
    "# Note: All JSON keys are strings. We will have to int(key) to read the data back.\n",
    "json.dump(\n",
    "    node_embedding_dict,\n",
    "    io.TextIOWrapper(\n",
    "        gzip.GzipFile(\"data/node_embedding_dict.json.gz\", \"w\"),\n",
    "        encoding=\"utf-8\",\n",
    "    ),\n",
    "    indent=4,\n",
    "    sort_keys=True,\n",
    ")\n",
    "\n",
    "# Write the entire network using GEXF format - the date has to be in UTC format for this to work.\n",
    "nx.write_gexf(G, path=\"data/physics_embeddings.gexf\", prettyprint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a32b3-319e-43ac-ab12-a4d906018c2d",
   "metadata": {},
   "source": [
    "# Label Making and K-Nearest-Neighbors (KNN) Graph Building\n",
    "\n",
    "Now we are going to build a pandas `DataFrame` or `pd.DataFrame` of our nodes so we can create clean labels for our journals. These will serve as labels for our machine-learning tasks using this network.\n",
    "\n",
    "In this section, we will also demonstrate another method of building a network - K-nearest-neighbors construction.\n",
    "\n",
    "## Building a Node `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65ea0cd4-6b8d-40b6-a3d9-af30157e999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequential_id</th>\n",
       "      <th>Paper</th>\n",
       "      <th>From</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Report-no</th>\n",
       "      <th>Published</th>\n",
       "      <th>Embedding-JSON</th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>hep-th/0001001</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>Sat, 1 Jan 2000 00:02:31 GMT</td>\n",
       "      <td>Compactification, Geometry and Duality: N=2</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>82 pages, 8 figures, LaTeX2e, TASI99, refs add...</td>\n",
       "      <td>DUKE-CGTP-00-01</td>\n",
       "      <td>946684800.0</td>\n",
       "      <td>[-0.508336067199707, -0.35725438594818115, 0.1...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9304045</td>\n",
       "      <td>1</td>\n",
       "      <td>hep-th/9304045</td>\n",
       "      <td></td>\n",
       "      <td>Sun, 11 Apr 93 12:29:30 -0500</td>\n",
       "      <td>Generalized Calabi-Yau Manifolds and the Mirro...</td>\n",
       "      <td>P. Candelas, E. Derrick and L. Parkes</td>\n",
       "      <td>39 pages, plain TeX</td>\n",
       "      <td>CERN-TH.6831/93, UTTG-24-92</td>\n",
       "      <td></td>\n",
       "      <td>[-0.7195298075675964, 0.002133328467607498, 0....</td>\n",
       "      <td>Nucl.Phys. B407 (1993) 115-154</td>\n",
       "      <td>We describe the mirror of the Z orbifold as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9308122</td>\n",
       "      <td>2</td>\n",
       "      <td>hep-th/9308122</td>\n",
       "      <td></td>\n",
       "      <td>Thu, 26 Aug 93 14:09:47 SET</td>\n",
       "      <td>Mirror Symmetry, Mirror Map and Applications t...</td>\n",
       "      <td>S. Hosono, A. Klemm, S. Theisen</td>\n",
       "      <td>59 pages. Some changes in the references, a fe...</td>\n",
       "      <td>HUTMP-93/0801, LMU-TPW-93-22</td>\n",
       "      <td></td>\n",
       "      <td>[-0.7420704364776611, -0.24777598679065704, -0...</td>\n",
       "      <td>Commun.Math.Phys. 167 (1995) 301-350</td>\n",
       "      <td>Mirror Symmetry, Picard-Fuchs equations and in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9309097</td>\n",
       "      <td>3</td>\n",
       "      <td>hep-th/9309097</td>\n",
       "      <td></td>\n",
       "      <td>Fri, 17 Sep 93 17:18:41 EDT</td>\n",
       "      <td>Calabi-Yau Moduli Space, Mirror Manifolds and ...</td>\n",
       "      <td>P.S. Aspinwall, B.R. Greene and D.R. Morrison</td>\n",
       "      <td>74 pages (with 20 figures)</td>\n",
       "      <td>IASSNS-HEP-93/38, CNLS-93/1236</td>\n",
       "      <td></td>\n",
       "      <td>[-0.29769614338874817, -0.12492246925830841, -...</td>\n",
       "      <td>Nucl.Phys. B416 (1994) 414-480</td>\n",
       "      <td>We analyze the moduli spaces of Calabi-Yau thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9311042</td>\n",
       "      <td>4</td>\n",
       "      <td>hep-th/9311042</td>\n",
       "      <td></td>\n",
       "      <td>Sun, 7 Nov 93 23:00:47 EST</td>\n",
       "      <td>Measuring Small Distances in N=2 Sigma Models</td>\n",
       "      <td>Paul S. Aspinwall, Brian R. Greene, and David ...</td>\n",
       "      <td>62 pp. with 6 figs., LaTeX and epsf.tex</td>\n",
       "      <td>IASSNS-HEP-93/49</td>\n",
       "      <td></td>\n",
       "      <td>[-0.48961982131004333, -0.17171087861061096, 0...</td>\n",
       "      <td>Nucl.Phys. B420 (1994) 184-242</td>\n",
       "      <td>We analyze global aspects of the moduli space ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node  file_id  sequential_id           Paper               From  \\\n",
       "0     0     1001              0  hep-th/0001001  Paul S. Aspinwall   \n",
       "1     1  9304045              1  hep-th/9304045                      \n",
       "2     2  9308122              2  hep-th/9308122                      \n",
       "3     3  9309097              3  hep-th/9309097                      \n",
       "4     4  9311042              4  hep-th/9311042                      \n",
       "\n",
       "                            Date  \\\n",
       "0   Sat, 1 Jan 2000 00:02:31 GMT   \n",
       "1  Sun, 11 Apr 93 12:29:30 -0500   \n",
       "2    Thu, 26 Aug 93 14:09:47 SET   \n",
       "3    Fri, 17 Sep 93 17:18:41 EDT   \n",
       "4     Sun, 7 Nov 93 23:00:47 EST   \n",
       "\n",
       "                                               Title  \\\n",
       "0        Compactification, Geometry and Duality: N=2   \n",
       "1  Generalized Calabi-Yau Manifolds and the Mirro...   \n",
       "2  Mirror Symmetry, Mirror Map and Applications t...   \n",
       "3  Calabi-Yau Moduli Space, Mirror Manifolds and ...   \n",
       "4      Measuring Small Distances in N=2 Sigma Models   \n",
       "\n",
       "                                             Authors  \\\n",
       "0                                  Paul S. Aspinwall   \n",
       "1              P. Candelas, E. Derrick and L. Parkes   \n",
       "2                    S. Hosono, A. Klemm, S. Theisen   \n",
       "3      P.S. Aspinwall, B.R. Greene and D.R. Morrison   \n",
       "4  Paul S. Aspinwall, Brian R. Greene, and David ...   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  82 pages, 8 figures, LaTeX2e, TASI99, refs add...   \n",
       "1                                39 pages, plain TeX   \n",
       "2  59 pages. Some changes in the references, a fe...   \n",
       "3                         74 pages (with 20 figures)   \n",
       "4            62 pp. with 6 figs., LaTeX and epsf.tex   \n",
       "\n",
       "                        Report-no    Published  \\\n",
       "0                 DUKE-CGTP-00-01  946684800.0   \n",
       "1     CERN-TH.6831/93, UTTG-24-92                \n",
       "2    HUTMP-93/0801, LMU-TPW-93-22                \n",
       "3  IASSNS-HEP-93/38, CNLS-93/1236                \n",
       "4                IASSNS-HEP-93/49                \n",
       "\n",
       "                                      Embedding-JSON  \\\n",
       "0  [-0.508336067199707, -0.35725438594818115, 0.1...   \n",
       "1  [-0.7195298075675964, 0.002133328467607498, 0....   \n",
       "2  [-0.7420704364776611, -0.24777598679065704, -0...   \n",
       "3  [-0.29769614338874817, -0.12492246925830841, -...   \n",
       "4  [-0.48961982131004333, -0.17171087861061096, 0...   \n",
       "\n",
       "                            Journal-ref  \\\n",
       "0                                         \n",
       "1        Nucl.Phys. B407 (1993) 115-154   \n",
       "2  Commun.Math.Phys. 167 (1995) 301-350   \n",
       "3        Nucl.Phys. B416 (1994) 414-480   \n",
       "4        Nucl.Phys. B420 (1994) 184-242   \n",
       "\n",
       "                                            Abstract  \n",
       "0                                                     \n",
       "1  We describe the mirror of the Z orbifold as a ...  \n",
       "2  Mirror Symmetry, Picard-Fuchs equations and in...  \n",
       "3  We analyze the moduli spaces of Calabi-Yau thr...  \n",
       "4  We analyze global aspects of the moduli space ...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract nodes and their attributes into a list of dictionaries\n",
    "node_data = [{**{\"node\": node}, **attr} for node, attr in G.nodes(data=True)]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "node_df = pd.DataFrame(node_data)\n",
    "\n",
    "# Cleanup\n",
    "node_df.fillna(\"\", inplace=True)\n",
    "\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83edc4-87f5-483b-874b-e4715569dbb0",
   "metadata": {},
   "source": [
    "## Clustering `Journal-ref`\n",
    "\n",
    "Taking a look at the field representing the journal a paper appeared in, we have a problem if we want to use this field as a label for a categorical classification... this is a fuzzy string problem, not a regular expression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d92b9e53-2e5b-4896-998f-5661722acb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2080         Phys.Lett. B289 (1992) 309-316\n",
       "448          Phys.Rev. D55 (1997) 6382-6393\n",
       "6745         Phys.Lett. B411 (1997) 261-267\n",
       "6717         Phys.Rev. D56 (1997) 6388-6390\n",
       "5212         J.Math.Phys. 42 (2001) 434-452\n",
       "25352                                      \n",
       "2628     Class. Quant. Grav. 12 (1995) 1021\n",
       "2886         Nucl.Phys. B523 (1998) 311-343\n",
       "7104       Helv.Phys.Acta 70 (1997) 247-274\n",
       "24352      J.Math.Phys. 35 (1994) 4839-4847\n",
       "Name: Journal-ref, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df[\"Journal-ref\"].sample(n=10).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ab1d4-98e8-458e-80eb-1226342d7a6d",
   "metadata": {},
   "source": [
    "### Embedding `Title`, `Abstract` and `Journal-ref`\n",
    "\n",
    "That's ok! We will embed the `Journal-ref` field and cluster it to arrive at our class labels for each journal. This will give us a head start on presenting network construction using K-Nearest-Neighbors in the next section :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45bf4e54-40a5-4dc9-b77b-86e4ff42d17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      \n",
       "1             NuclPhysB\n",
       "2        CommunMathPhys\n",
       "3             NuclPhysB\n",
       "4             NuclPhysB\n",
       "              ...      \n",
       "27765     IntJTheorPhys\n",
       "27766          JPhysALL\n",
       "27767          PhysRevD\n",
       "27768         NuclPhysB\n",
       "27769                  \n",
       "Name: Journal-ref-Letters, Length: 27770, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1. Embed the dirty Journal-ref and cluster it to produce journal class labels.\n",
    "paraphrase_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed these columns\n",
    "embeddings: Dict[str, np.ndarray] = {}\n",
    "# for column in [\"Title\", \"Abstract\", \"Journal-ref\"]:\n",
    "#     column_embedding = paraphrase_model.encode(node_df[column].tolist())\n",
    "#     embeddings[column] = column_embedding\n",
    "#     node_df[f\"{column}-Embedding\"] = embeddings[column].tolist()\n",
    "\n",
    "# Remove all non-text characters from Journal-ref to make it cluster better\n",
    "node_df[\"Journal-ref-Letters\"] = node_df[\"Journal-ref\"].str.replace(r\"[^a-zA-Z]\", \"\", regex=True)\n",
    "node_df[\"Journal-ref-Letters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "945af2a3-eb9c-4d1d-9b33-0ae129c34fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.11883842,  0.04829863, -0.00254808, ...,  0.12640953,\n",
       "          0.04654901, -0.01571725],\n",
       "        [-0.01090816,  0.01571381, -0.08676197, ..., -0.07030743,\n",
       "          0.02916013,  0.03203483],\n",
       "        [ 0.03590528,  0.00795958,  0.00348998, ...,  0.08304361,\n",
       "          0.0570259 ,  0.00842906],\n",
       "        ...,\n",
       "        [-0.07949313, -0.0807268 , -0.00690103, ...,  0.0029123 ,\n",
       "          0.09107167, -0.01444742],\n",
       "        [-0.01090813,  0.0157138 , -0.08676196, ..., -0.07030747,\n",
       "          0.02916011,  0.03203484],\n",
       "        [-0.11883841,  0.04829867, -0.00254807, ...,  0.12640947,\n",
       "          0.046549  , -0.01571729]], dtype=float32),\n",
       " (27770, 384))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"Journal-ref\"] = model.encode(node_df[\"Journal-ref-Letters\"].tolist())\n",
    "embeddings[\"Journal-ref\"], embeddings[\"Journal-ref\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "18dca36e-5762-43d3-8eeb-e7de2b91d395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Journal-ref-Letters</th>\n",
       "      <th>Journal-ref-Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nucl.Phys. B407 (1993) 115-154</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>[-0.010908156633377075, 0.01571381464600563, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commun.Math.Phys. 167 (1995) 301-350</td>\n",
       "      <td>CommunMathPhys</td>\n",
       "      <td>[0.03590528294444084, 0.007959578186273575, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nucl.Phys. B416 (1994) 414-480</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>[-0.010908156633377075, 0.01571381464600563, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nucl.Phys. B420 (1994) 184-242</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>[-0.010908156633377075, 0.01571381464600563, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phys.Rept. 244 (1994) 77-202</td>\n",
       "      <td>PhysRept</td>\n",
       "      <td>[-0.07043598592281342, -0.08629656583070755, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Journal-ref Journal-ref-Letters  \\\n",
       "0                                                             \n",
       "1        Nucl.Phys. B407 (1993) 115-154           NuclPhysB   \n",
       "2  Commun.Math.Phys. 167 (1995) 301-350      CommunMathPhys   \n",
       "3        Nucl.Phys. B416 (1994) 414-480           NuclPhysB   \n",
       "4        Nucl.Phys. B420 (1994) 184-242           NuclPhysB   \n",
       "5          Phys.Rept. 244 (1994) 77-202            PhysRept   \n",
       "\n",
       "                               Journal-ref-Embedding  \n",
       "0  [-0.11883842200040817, 0.04829862713813782, -0...  \n",
       "1  [-0.010908156633377075, 0.01571381464600563, -...  \n",
       "2  [0.03590528294444084, 0.007959578186273575, 0....  \n",
       "3  [-0.010908156633377075, 0.01571381464600563, -...  \n",
       "4  [-0.010908156633377075, 0.01571381464600563, -...  \n",
       "5  [-0.07043598592281342, -0.08629656583070755, -...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df[\"Journal-ref-Embedding\"] = embeddings[\"Journal-ref\"].tolist()\n",
    "node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-Embedding\"]].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a61bc497-e340-4d30-8a5b-97a17ce6f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_df[[\"Title\", \"Title-Embedding\", \"Abstract\", \"Abstract-Embedding\", \"Journal-ref\", \"Journal-ref-Embedding\"]].sample(6).head(6)\n",
    "# node_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622cf8-0814-43fe-86a6-b1680754610d",
   "metadata": {},
   "source": [
    "### Clustering `Journal-ref-Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7b59b2d3-e144-4c9d-b9ea-b0f683e4ca3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.0308799 ,  0.6584773 ,  0.5440046 , ...,  1.2649735 ,\n",
       "          0.02596419, -0.05070024],\n",
       "        [ 1.6256564 ,  0.03988452, -1.2670246 , ..., -1.5191159 ,\n",
       "         -0.4508596 ,  0.9586046 ],\n",
       "        [ 2.777897  , -0.10732255,  0.67385393, ...,  0.65122575,\n",
       "          0.31325278,  0.45966467],\n",
       "        ...,\n",
       "        [-0.06245632, -1.7909521 ,  0.45039397, ..., -0.4828542 ,\n",
       "          1.2468283 , -0.02386072],\n",
       "        [ 1.625657  ,  0.03988416, -1.2670243 , ..., -1.5191165 ,\n",
       "         -0.4508601 ,  0.9586049 ],\n",
       "        [-1.0308796 ,  0.6584781 ,  0.54400486, ...,  1.2649727 ,\n",
       "          0.02596378, -0.05070111]], dtype=float32),\n",
       " (27770, 384))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's a good practice to scale the data to have a mean = 0 and variance = 1.\n",
    "# This helps UMAP and DBSCAN perform better\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(embeddings[\"Journal-ref\"])\n",
    "\n",
    "scaled_embeddings, scaled_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0920893c-b620-4bac-bffa-32c419d1b880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27770,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(\n",
    "    n_clusters=30, \n",
    "    max_iter=300, \n",
    "    tol=1e-04, \n",
    "    init='k-means++', \n",
    "    n_init=10, \n",
    "    random_state=31337, \n",
    "    algorithm='lloyd'\n",
    ")\n",
    "class_scores = km.fit_transform(scaled_embeddings)\n",
    "classes = np.argmax(cluster_scores, axis=1)\n",
    "\n",
    "np.unique(classes, return_counts=True)\n",
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "78a52bee-c522-4553-9529-e36c91fc3c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Journal-ref-Letters</th>\n",
       "      <th>Journal-ref-Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nucl.Phys. B407 (1993) 115-154</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commun.Math.Phys. 167 (1995) 301-350</td>\n",
       "      <td>CommunMathPhys</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nucl.Phys. B416 (1994) 414-480</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nucl.Phys. B420 (1994) 184-242</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phys.Rept. 244 (1994) 77-202</td>\n",
       "      <td>PhysRept</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mirror Symmetry II (B. Greene and S.-T. Yau, e...</td>\n",
       "      <td>MirrorSymmetryIIBGreeneandSTYauedsInternational</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nucl.Phys. B426 (1994) 19-52; Erratum-ibid. B4...</td>\n",
       "      <td>NuclPhysBErratumibidB</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nucl.Phys. B431 (1994) 484-550</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nucl.Phys. B442 (1995) 47-63</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Journal-ref  \\\n",
       "0                                                      \n",
       "1                     Nucl.Phys. B407 (1993) 115-154   \n",
       "2               Commun.Math.Phys. 167 (1995) 301-350   \n",
       "3                     Nucl.Phys. B416 (1994) 414-480   \n",
       "4                     Nucl.Phys. B420 (1994) 184-242   \n",
       "5                       Phys.Rept. 244 (1994) 77-202   \n",
       "6  Mirror Symmetry II (B. Greene and S.-T. Yau, e...   \n",
       "7  Nucl.Phys. B426 (1994) 19-52; Erratum-ibid. B4...   \n",
       "8                     Nucl.Phys. B431 (1994) 484-550   \n",
       "9                       Nucl.Phys. B442 (1995) 47-63   \n",
       "\n",
       "                               Journal-ref-Letters  Journal-ref-Classes  \n",
       "0                                                                    18  \n",
       "1                                        NuclPhysB                   10  \n",
       "2                                   CommunMathPhys                   13  \n",
       "3                                        NuclPhysB                   15  \n",
       "4                                        NuclPhysB                    0  \n",
       "5                                         PhysRept                   10  \n",
       "6  MirrorSymmetryIIBGreeneandSTYauedsInternational                    0  \n",
       "7                            NuclPhysBErratumibidB                   15  \n",
       "8                                        NuclPhysB                   15  \n",
       "9                                        NuclPhysB                   17  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df[\"Journal-ref-Classes\"] = classes\n",
    "node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-Classes\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "86d439e1-4b7f-4944-831b-355788317496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x0, y0, sigma = 5.5, 4.2, 1.4\n",
    "\n",
    "x, y = np.arange(9), np.arange(9)\n",
    "\n",
    "gx = np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "gy = np.exp(-(y-y0)**2/(2*sigma**2))\n",
    "g = np.outer(gx, gy)\n",
    "g /= np.sum(g)  # normalize, if you want that\n",
    "\n",
    "plt.imshow(g, interpolation=\"nearest\", origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6ac9ad4a-14b1-4e8c-bb06-309b309f8b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/manifold/_spectral_embedding.py:274: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  0.5297564 ,   1.9965926 ],\n",
       "        [ 14.698434  ,   0.91303813],\n",
       "        [ 18.042261  ,   7.9776754 ],\n",
       "        ...,\n",
       "        [  5.6404557 ,  -8.507432  ],\n",
       "        [ -4.5596957 , -14.740852  ],\n",
       "        [-13.190072  ,  -7.1550746 ]], dtype=float32),\n",
       " (27770, 2))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Dimension Reduction with UMAP\n",
    "reducer = umap.UMAP()\n",
    "reduced_embeddings = reducer.fit_transform(scaled_embeddings)\n",
    "\n",
    "reduced_embeddings, reduced_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dca51b0b-2fcb-4aab-b6eb-c8b610b01e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]),\n",
       " array([2332, 7005, 2474,  379,  188, 2381, 3074,  210,  261, 1032,  264,\n",
       "         468,  149, 1955, 1136,  497,  575,  242,  360,  275,  336,  287,\n",
       "         512,  269,  112,  132,  190,  444,  105,  126]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Clustering with DBSCAN - you can search for the best hyperparameters\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=100)\n",
    "clusters = dbscan.fit_predict(reduced_embeddings)\n",
    "np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f54ebadd-71d5-4129-8ceb-16826377e867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Journal-ref-Letters</th>\n",
       "      <th>Journal-ref-Classes</th>\n",
       "      <th>Journal-ref-DBSCAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nucl.Phys. B407 (1993) 115-154</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commun.Math.Phys. 167 (1995) 301-350</td>\n",
       "      <td>CommunMathPhys</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nucl.Phys. B416 (1994) 414-480</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nucl.Phys. B420 (1994) 184-242</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phys.Rept. 244 (1994) 77-202</td>\n",
       "      <td>PhysRept</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mirror Symmetry II (B. Greene and S.-T. Yau, e...</td>\n",
       "      <td>MirrorSymmetryIIBGreeneandSTYauedsInternational</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nucl.Phys. B426 (1994) 19-52; Erratum-ibid. B4...</td>\n",
       "      <td>NuclPhysBErratumibidB</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nucl.Phys. B431 (1994) 484-550</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nucl.Phys. B442 (1995) 47-63</td>\n",
       "      <td>NuclPhysB</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Journal-ref  \\\n",
       "0                                                      \n",
       "1                     Nucl.Phys. B407 (1993) 115-154   \n",
       "2               Commun.Math.Phys. 167 (1995) 301-350   \n",
       "3                     Nucl.Phys. B416 (1994) 414-480   \n",
       "4                     Nucl.Phys. B420 (1994) 184-242   \n",
       "5                       Phys.Rept. 244 (1994) 77-202   \n",
       "6  Mirror Symmetry II (B. Greene and S.-T. Yau, e...   \n",
       "7  Nucl.Phys. B426 (1994) 19-52; Erratum-ibid. B4...   \n",
       "8                     Nucl.Phys. B431 (1994) 484-550   \n",
       "9                       Nucl.Phys. B442 (1995) 47-63   \n",
       "\n",
       "                               Journal-ref-Letters  Journal-ref-Classes  \\\n",
       "0                                                                    18   \n",
       "1                                        NuclPhysB                   10   \n",
       "2                                   CommunMathPhys                   13   \n",
       "3                                        NuclPhysB                   15   \n",
       "4                                        NuclPhysB                    0   \n",
       "5                                         PhysRept                   10   \n",
       "6  MirrorSymmetryIIBGreeneandSTYauedsInternational                    0   \n",
       "7                            NuclPhysBErratumibidB                   15   \n",
       "8                                        NuclPhysB                   15   \n",
       "9                                        NuclPhysB                   17   \n",
       "\n",
       "   Journal-ref-DBSCAN  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   2  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                  -1  \n",
       "6                   3  \n",
       "7                  -1  \n",
       "8                   1  \n",
       "9                   1  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df[\"Journal-ref-DBSCAN\"] = clusters\n",
    "node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-Classes\", \"Journal-ref-DBSCAN\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391cf07-c757-4972-9ce4-100b4cad98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, each point has a cluster label, which could be -1 for noise points\n",
    "node_df[\"Cluster\"] = clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
