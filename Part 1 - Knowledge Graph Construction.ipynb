{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5319f2-b647-4bcc-90b2-8f748ed39eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/opt/conda/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/opt/conda/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/opt/conda/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "import gzip\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "from datetime import date\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import graphistry\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import Tensor\n",
    "\n",
    "sns.set(style='white', context='poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312d8d-ed3d-4f0d-811f-58d5c810a8c1",
   "metadata": {},
   "source": [
    "Part 1: Knowledge Graph Construction\n",
    "====================================\n",
    "\n",
    "In this section of the course, we will cover _knowledge graph construction_ or how to construct knowledge graphs from both _natural networks_ and _structural networks_. In the lecture I described _knowledge graph construction_ as the process of building a knowledge graph from raw data using ETL, data transformations or Natural Language Processing (NLP).\n",
    "\n",
    "There are two main types of networks in common use: simple and heterogeneous networks. We're going to start out building a simple network where nodes are _academic papers_ and edges are _citations between papers_.\n",
    "\n",
    "<center><img src=\"images/Graphs-vs-Heterogeneous-Graphs-2000px.png\" width=\"1000px\" /></center>\n",
    "\n",
    "There are two categories of data from which we can build networks: _natural networks_ and _structural networks_. We can also transform _existing networks_ that are already formatted and easy to work with.\n",
    "\n",
    "<center><img src=\"images/ETL-in-Natural-and-Structural-Graphs.jpg\" width=\"860px\" /></center>\n",
    "\n",
    "Structural networks are just as important as natural networks because...\n",
    "\n",
    "<center><img src=\"images/Raw-Data-are-Often-Not-Networks.png\" width=\"960px\" /></center>\n",
    "<center>Slide on Network Construction from <a href=\"https://scholar.google.com/citations?user=Q_kKkIUAAAAJ&hl=en&oi=ao\">Jure Leskovec's</a> <a href=\"https://web.stanford.edu/class/cs224w/\">Stanford CS224W class</a> when it was still called <i>Network Analysis</i>. Today it is called <i>Machine Learning with Graphs</i></center>\n",
    "\n",
    "<br />\n",
    "\n",
    "Given time, we'll be building both _simple_ and _heterogeneous networks_ from both _natural_ and _structural graphs_. We'll start with the former.\n",
    "\n",
    "# Section Textbook\n",
    "\n",
    "An excellent resource for the first two parts of this course, **Knowledge Graph Construction** and **Network Science** is the [Network Science (CC4063 / CC4095)](https://www.dcc.fc.up.pt/~pribeiro/aulas/ns2122/) class taught by [Pedro Ribeiro](https://www.dcc.fc.up.pt/~pribeiro/) at the [Center for Research in Advanced Computing Systems](https://cracs.fc.up.pt/), part of the [Computer Science Department](https://www.dcc.fc.up.pt/site/) of the [University of Porto](https://www.up.pt/portal/en/).\n",
    "\n",
    "We will be using [Section 10: Network Construction](https://www.dcc.fc.up.pt/~pribeiro/aulas/ns2122/handouts.html#construction) during this part of the course, and specifically the slides for that section: [Network Construction (selected slides from J. Leskovec and L. Lacasa)](https://www.dcc.fc.up.pt/~pribeiro/aulas/ns2122/10_netconstruction.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33276594-d0c7-4a44-8637-a5426107134e",
   "metadata": {},
   "source": [
    "# Setting up Graphistry\n",
    "\n",
    "First let's setup a network visualization tool to help us evaluate what we are building. Throughout this part of the course we will be using `pygraphistry` and [Graphistry Hub](https://hub.graphistry.com/) [https://hub.graphistry.com/](https://hub.graphistry.com/) to visualize networks. Both are free for personal use and are powerful for visualizing networks large and small.\n",
    "\n",
    "You can [signup](https://hub.graphistry.com/accounts/signup/) for a Graphistry account at [https://hub.graphistry.com/accounts/signup/](https://hub.graphistry.com/accounts/signup/). <b>You should use a username/password/email to get the required credentials</b>, although after that you can login with your Github or Google account.\n",
    "\n",
    "<center><img src=\"images/graphistry_hub_registration.png\" /></center>\n",
    "\n",
    "Retain and use your credentials in the login form and in the environment variables in the next cell below. You should set the `GRAPHISTRY_USERNAME` and `GRAPHISTRY_PASSWORD` variables in the `env/graphistry.env` file, and then restart this docker container to pickup the new values.\n",
    "\n",
    "<center><img src=\"images/graphistry_hub_homepage.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94962741-ff18-417f-a218-52e6a61f5a0e",
   "metadata": {},
   "source": [
    "# ETL for a Simple, Natural Graph: High-energy Physics Theory Citation Network\n",
    "\n",
    "We are going to start out by building a knowledge graph from an existing edge list and then add properties to it. We'll be using the [High-energy physics theory citation network](https://snap.stanford.edu/data/cit-HepTh.html) from [Stanford SNAP](https://snap.stanford.edu/index.html). SNAP has many large network datasets available in the [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/).\n",
    "\n",
    "The dataset includes the following files, which we will combine:\n",
    "\n",
    "* [Citation graph edge list](https://snap.stanford.edu/data/cit-HepTh.txt.gz) contains node ID pairs. Node IDs are standard paper identifiers. This will build the core structure of our network.\n",
    "* [Paper metadata](cit-HepTh-abstracts.tar.gz) including abstracts. This will add propertis to our network.\n",
    "* [Publishing dates on arXiv](https://snap.stanford.edu/data/cit-HepTh-dates.txt.gz) will make our citation network a temporal [Directed-Acyclic-Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) since one paper can't cite another before it is written and there are no reciprocal edges. While we don't focus on this, it does affect our analysis.\n",
    "\n",
    "## Dataset Citation\n",
    "\n",
    "```\n",
    "Paper: hep-th/0002031\n",
    "From: Maulik K. Parikh \n",
    "Date: Fri, 4 Feb 2000 17:04:51 GMT   (10kb)\n",
    "\n",
    "Title: Confinement and the AdS/CFT Correspondence\n",
    "Authors: D. S. Berman and Maulik K. Parikh\n",
    "Comments: 12 pages, 1 figure, RevTeX\n",
    "Report-no: SPIN-1999/25, UG-1999/42\n",
    "Journal-ref: Phys.Lett. B483 (2000) 271-276\n",
    "\\\\\n",
    "  We study the thermodynamics of the confined and unconfined phases of\n",
    "superconformal Yang-Mills in finite volume and at large N using the AdS/CFT\n",
    "correspondence. We discuss the necessary conditions for a smooth phase\n",
    "crossover and obtain an N-dependent curve for the phase boundary.\n",
    "\\\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c191a7-0372-4723-9909-cefd2afc61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variable setup\n",
    "GRAPHISTRY_USERNAME = os.getenv(\"GRAPHISTRY_USERNAME\")\n",
    "GRAPHISTRY_PASSWORD = os.getenv(\"GRAPHISTRY_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e92082-faad-40a2-836e-ca7f98c5f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphistry.register(\n",
    "    api=3,\n",
    "    username=GRAPHISTRY_USERNAME,\n",
    "    password=GRAPHISTRY_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09972cd9-b909-445f-8b78-94d1978b4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Graphistry\n",
    "GRAPHISTRY_PARAMS = {\n",
    "    \"play\": 600,\n",
    "    \"pointOpacity\": 0.7,\n",
    "    \"edgeOpacity\": 0.3,\n",
    "    \"edgeCurvature\": 0.3,\n",
    "    \"showArrows\": True,\n",
    "    \"gravity\": 0.5,\n",
    "}\n",
    "FAVICON_URL = \"https://graphlet.ai/assets/icons/favicon.ico\"\n",
    "LOGO = {\"url\": \"https://graphlet.ai/assets/Branding/Graphlet%20AI.svg\", \"dimensions\": {\"maxWidth\": 100, \"maxHeight\": 100}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3cf16-524f-49a0-9865-eb5924e357d1",
   "metadata": {},
   "source": [
    "## `NetworkX` on PyPi is `networkx` in code is `nx`.\n",
    "\n",
    "The convention we used above is to load NetworkX via `import networkx as nx` so we can use the shorthand `nx` to call its classes and algorithms.\n",
    "\n",
    "## Numeric Node IDs\n",
    "\n",
    "What follows is a demonstration of _knowledge graph construction_, which we covered in the lecture. A node/edge list was provided, but the IDs are not sequential... which a network sampling tool I hope to use called [littleballoffur](https://github.com/benedekrozemberczki/littleballoffur) requires. In fact many graph libraries require sequential IDs. We must transform the graph IDs, create a mapping back and forth and annotate the nodes with properties for both IDs.\n",
    "\n",
    "## Build a Directional Graph (nx.DiGraph) from a CSV\n",
    "\n",
    "The edge list is a `#` commented, space-delimited CSV. We will parse it, assign sequential IDs and build a [`nx.DiGraph`](https://networkx.org/documentation/stable/reference/classes/digraph.html).\n",
    "\n",
    "### Download the Citation Edge List\n",
    "\n",
    "First, we download the edge list and build the structure of the network: `(paper)-cited->(paper)`. Note that we cache the edge list so you can edit the code without having to re-download the data.\n",
    "\n",
    "The edge list is located at [https://snap.stanford.edu/data/cit-HepTh.txt.gz](https://snap.stanford.edu/data/cit-HepTh.txt.gz) and is stored in `data/cit-HepTh.txt.gz`. We will read the file in its compressed state via the `gzip` builtin library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4b88f4-deaf-444a-b90f-10bd9b7dad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing citation graph edge file data/cit-HepTh.txt.gz\n"
     ]
    }
   ],
   "source": [
    "# Download and load edges (citations) from `cit-HepTh.txt.gz`\n",
    "edge_path = \"data/cit-HepTh.txt.gz\"\n",
    "gzip_content = None\n",
    "\n",
    "if os.path.exists(edge_path):\n",
    "    print(f\"Using existing citation graph edge file {edge_path}\")\n",
    "    gzip_content = open(edge_path, \"rb\")\n",
    "else:\n",
    "    print(\"Fetching citation graph edge file ...\")\n",
    "    response = requests.get(f\"https://snap.stanford.edu/{edge_path}\")\n",
    "    gzip_content = io.BytesIO(response.content)\n",
    "\n",
    "    print(\"Writing edge list to file {edge_path}\")\n",
    "    with open(edge_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "        print(f\"Wrote downloaded edge file to {edge_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1ba635-1606-4e15-9b2f-795b79e44753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Directed graph (each unordered pair of nodes is saved once): Cit-HepTh.txt \n",
      "# Paper citation network of Arxiv High Energy Physics Theory category\n",
      "# Nodes: 27770 Edges: 352807\n",
      "# FromNodeId\tToNodeId\n",
      "1001\t9304045\n",
      "1001\t9308122\n",
      "1001\t9309097\n",
      "1001\t9311042\n",
      "1001\t9401139\n",
      "1001\t9404151\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Check the top 10 lines of our gzip text file\n",
    "!zcat data/cit-HepTh.txt.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88106b1c-c9a1-4ebe-82e2-a54d2b31df9e",
   "metadata": {},
   "source": [
    "### Graph and Identifier Setup\n",
    "\n",
    "We create directional a [`nx.DiGraph`](https://networkx.org/documentation/stable/reference/classes/digraph.html) because citations are inherently directional: from citer to cited. Note that whether we model them this way or not, citation graphs are temporal networks. The citing paper's publishing date must fall after cited paper's publishing date. We'll load publishing dates below.\n",
    "\n",
    "We need to setup `file_to_net` and `net_to_file` dictionaries to map back and forth between the file format's identifiers and or own sequential identifiers we'll be assigning starting with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b66727-06b4-4c72-b02a-1caf2a66242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a directed graph\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c3f84c-c441-46f1-988b-7bca8c561a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create sequential IDs starting from 0 for littleballoffur and DGL\n",
    "file_to_net: Dict[int, int] = {}\n",
    "net_to_file: Dict[int, int] = {}\n",
    "current_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ae24c-b54d-4a5a-b286-c5f0288eaab4",
   "metadata": {},
   "source": [
    "### From Text to Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd66174-f00d-448d-be65-b68787ea7adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network structure ...\n",
      "Network built! It contains 27,770 nodes and 352,807 edges.\n"
     ]
    }
   ],
   "source": [
    "# Decompress the gzip content and build the edge list for our network\n",
    "print(\"Building network structure ...\")\n",
    "\n",
    "# Note we reuse the `gzip_content` variable from the download cell. This is a weird way to do it :)\n",
    "with gzip.GzipFile(fileobj=gzip_content) as f:\n",
    "\n",
    "    # Iterate through the lines, using the `line_number` as an `edge_id` below.\n",
    "    # They won't quite start at 0 owing to comments, but that's ok in the case of edges.\n",
    "    for line_number, line in enumerate(f):\n",
    "        line = line.decode(\"utf-8\")\n",
    "\n",
    "        # Ignore comment lines that start with '#'\n",
    "        if not line.startswith(\"#\"):\n",
    "            # Source (citing), desstination (cited) papers\n",
    "            citing_key, cited_key = line.strip().split(\"\\t\")\n",
    "\n",
    "            # The edge list makes the paper ID an int, stripping 0001001 to 1001, for example\n",
    "            citing_key, cited_key = int(citing_key), int(cited_key)\n",
    "\n",
    "            # If the either of the paper IDs don't exist, make one\n",
    "            for key in [citing_key, cited_key]:\n",
    "                if key not in file_to_net:\n",
    "                    # Build up an index that maps back and forth\n",
    "                    file_to_net[key] = current_idx\n",
    "                    net_to_file[current_idx] = key\n",
    "\n",
    "                    # Bump the current ID\n",
    "                    current_idx += 1\n",
    "\n",
    "            # print(f\"Citing key: {citing_key}, Cited key: {cited_key}\")\n",
    "            # print(f\"Mapped key: {file_to_net[citing_key]}, Mapped key: {file_to_net[cited_key]}\")\n",
    "\n",
    "            G.add_edge(file_to_net[citing_key], file_to_net[cited_key], edge_id=line_number)\n",
    "\n",
    "            # Conditionally set the keys on the nodes\n",
    "            G.nodes[file_to_net[citing_key]][\"file_id\"] = citing_key\n",
    "            G.nodes[file_to_net[citing_key]][\"sequential_id\"] = file_to_net[citing_key]\n",
    "\n",
    "            G.nodes[file_to_net[cited_key]][\"file_id\"] = cited_key\n",
    "            G.nodes[file_to_net[cited_key]][\"sequential_id\"] = file_to_net[cited_key]\n",
    "\n",
    "print(f\"Network built! It contains {G.number_of_nodes():,} nodes and {G.number_of_edges():,} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5d993-5545-4886-966a-e622d2409215",
   "metadata": {},
   "source": [
    "## Node Properties from Abstract Metadata\n",
    "\n",
    "In addition to the edge list, SNAP provides the paper's essential metadata in another file, which we will load to provide node properties and text embeddings for citation graph.\n",
    "\n",
    "We are going to perform the following steps:\n",
    "\n",
    "1) Download and cache the metadata to `data/cit-HepTh-abstracts.tar.gz`. Note that 1 file corresponds to one paper node's metadata.\n",
    "2) Process the tarball file where one file corresponds to one node ID in the original file. See why we made or mappings `file_to_net` and `net_to_file`?\n",
    "3) Assign node properties by parsing the fields of the record using traditional information extraction with regular expressions.\n",
    "4) Use a sentence transformer paraphrase model to summarize the entire textual record and enable node comparison for journal label creation.\n",
    "\n",
    "### Downloading the Abstract Metadata\n",
    "\n",
    "Another file containing node metadata, including the abstracts, for about 90% of nodes in this network is provided at [https://snap.stanford.edu/data/cit-HepTh-abstracts.tar.gz](https://snap.stanford.edu/data/cit-HepTh-abstracts.tar.gz), which we will save to `data/cit-HepTh-abstracts.tar.gz`. This code works just like the edge list download code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4609227a-1af3-41fd-9921-7715c11d9685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching paper abstracts ...\n",
      "Using existing paper abstracts file data/cit-HepTh-abstracts.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Download the abstracts from `cit-HepTh-abstracts.tar.gz`\n",
    "print(\"Fetching paper abstracts ...\")\n",
    "abstract_path = \"data/cit-HepTh-abstracts.tar.gz\"\n",
    "abstract_gzip_content = None\n",
    "\n",
    "if os.path.exists(abstract_path):\n",
    "    print(f\"Using existing paper abstracts file {abstract_path}\")\n",
    "    with open(abstract_path, \"rb\") as f:\n",
    "        abstract_gzip_content = io.BytesIO(f.read())\n",
    "else:\n",
    "    print(\"Downloading paper abbstracts ...\")\n",
    "    abstract_response = requests.get(f\"https://snap.stanford.edu/{abstract_path}\")\n",
    "    abstract_gzip_content = io.BytesIO(abstract_response.content)\n",
    "\n",
    "    print(f\"Downloading abstract file to {abstract_path}\")\n",
    "    with open(abstract_path, \"wb\") as f:\n",
    "        f.write(abstract_response.content)\n",
    "        print(f\"Wrote downloaded abstract file to {abstract_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee4892-b011-4b3b-bb18-78633a297a3b",
   "metadata": {},
   "source": [
    "### Manually Parsing Node Metadata\n",
    "\n",
    "As a first pass let's use regular expressions in the Python `re` builtin library to extract each paper's fields so we can assign them as properties to our `nx.DiGraph` nodes.\n",
    "\n",
    "Here is what a couple of **test documents** look like. This is corresponds to two files in our abstract tarball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce09eff3-3189-45c5-b139-3d346bf97e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "\"\"\"------------------------------------------------------------------------------\n",
    "\\\\\n",
    "Paper: hep-th/9612115\n",
    "From: Asato Tsuchiya <tsuchiya@theory.kek.jp>\n",
    "Date: Wed, 11 Dec 1996 17:38:56 +0900   (20kb)\n",
    "Date (revised): Tue, 31 Dec 1996 01:06:34 +0900\n",
    "\n",
    "Title: A Large-N Reduced Model as Superstring\n",
    "Authors: N. Ishibashi, H. Kawai, Y. Kitazawa and A. Tsuchiya\n",
    "Comments: 29 pages, Latex, a footnote and references added, eq.(3.52)\n",
    "corrected, minor corrections\n",
    "Report-no: KEK-TH-503, TIT/HEP-357\n",
    "Journal-ref: Nucl.Phys. B498 (1997) 467-491\n",
    "\\\\\n",
    "A matrix model which has the manifest ten-dimensional N=2 super Poincare\n",
    "invariance is proposed. Interactions between BPS-saturated states are analyzed\n",
    "to show that massless spectrum is the same as that of type IIB string theory.\n",
    "It is conjectured that the large-N reduced model of ten-dimensional super\n",
    "Yang-Mills theory can be regarded as a constructive definition of this model\n",
    "and therefore is equivalent to superstring theory.\n",
    "\\\\\n",
    "\"\"\",\n",
    "    \"\"\"------------------------------------------------------------------------------\n",
    "\\\\\n",
    "Paper: hep-th/9711029\n",
    "From: John Schwarz <jhs@theory.caltech.edu>\n",
    "Date: Wed, 5 Nov 1997 17:30:55 GMT   (20kb)\n",
    "Date (revised v2): Thu, 6 Nov 1997 23:52:45 GMT   (21kb)\n",
    "\n",
    "Title: The Status of String Theory\n",
    "Author: John H. Schwarz\n",
    "Comments: 16 pages, latex, two figures; minor corrections, references added\n",
    "Report-no: CALT-68-2140\n",
    "\\\\\n",
    "There have been many remarkable developments in our understanding of\n",
    "superstring theory in the past few years, a period that has been described as\n",
    "``the second superstring revolution.'' Several of them are discussed here. The\n",
    "presentation is intended primarily for the benefit of nonexperts.\n",
    "\\\\\n",
    "\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f48a8b-95b3-404e-8658-7c9fd4002acd",
   "metadata": {},
   "source": [
    "### Structured Information Extraction with a Regex Helper\n",
    "\n",
    "Our extract function was created through trial and error using the [Pythex Regex Editor](https://pythex.org/). Paste the test documents where it says `Your test data` and try a couple of the patterns such as `r\"\"` above that where it says `Your regular expression`. It will show you where the patterns match in your data. A new section displays the matches within the text and a window on the right shows the text your regular expression will return via the list the `match.groups()` command returns.\n",
    "\n",
    "A few cycles of this and we have a clean extraction. In practice, I used more test records than this, which I've spared you in the interest of time :) Regular expressions are difficult to learn, but there are resources and **ChatGPT-4 is quite capable at writing regex!** It wrote many of the ones below.\n",
    "\n",
    "<center><img src=\"images/Pythex-Regex-Helper.png\" width=\"1000px\" /></center>\n",
    "\n",
    "I used Pythex to help write the `extract_paper_info(record)` method below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b66d7e1-9e7a-4f51-adc2-7d26538b5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_info(record):\n",
    "    \"\"\"Extract structured information from the text of academic paper text records using regular expressions.\n",
    "\n",
    "    Note: I was written wholly or in part by ChatGPT4 on May 23, 2023.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary to hold the information\n",
    "    info = {}\n",
    "\n",
    "    # Match \"Paper\" field\n",
    "    paper_match = re.search(r\"Paper:\\s*(.*)\", record)\n",
    "    if paper_match:\n",
    "        info[\"Paper\"] = paper_match.group(1)\n",
    "\n",
    "    # # Match \"From\" field\n",
    "    # from_match = re.search(r\"From:\\s*(.*)\", record)\n",
    "    # if from_match:\n",
    "    #     info['From'] = from_match.group(1)\n",
    "\n",
    "    # Match \"From\" field\n",
    "    from_match = re.search(r\"From:\\s*([^<]*)<\", record)\n",
    "    if from_match:\n",
    "        info[\"From\"] = from_match.group(1).strip()\n",
    "\n",
    "    # Match \"Date\" field\n",
    "    date_match = re.search(r\"Date:\\s*(.*)(\\s*)(\\(\\d+kb\\))\", record)\n",
    "    if date_match:\n",
    "        info[\"Date\"] = date_match.group(1).strip()\n",
    "\n",
    "    # Match \"Title\" field\n",
    "    title_match = re.search(r\"Title:\\s*(.*)\", record)\n",
    "    if title_match:\n",
    "        info[\"Title\"] = title_match.group(1)\n",
    "\n",
    "    # Match \"Authors\" field\n",
    "    authors_match = re.search(r\"Authors:\\s*(.*)\", record)\n",
    "    if authors_match:\n",
    "        info[\"Authors\"] = authors_match.group(1)\n",
    "\n",
    "    # Match \"Comments\" field\n",
    "    comments_match = re.search(r\"Comments:\\s*(.*)\", record)\n",
    "    if comments_match:\n",
    "        info[\"Comments\"] = comments_match.group(1)\n",
    "\n",
    "    # Match \"Report-no\" field\n",
    "    report_no_match = re.search(r\"Report-no:\\s*(.*)\", record)\n",
    "    if report_no_match:\n",
    "        info[\"Report-no\"] = report_no_match.group(1)\n",
    "\n",
    "    # Match \"Journal-ref\" field\n",
    "    journal_ref_match = re.search(r\"Journal-ref:\\s*(.*)\", record)\n",
    "    if journal_ref_match:\n",
    "        info[\"Journal-ref\"] = journal_ref_match.group(1)\n",
    "\n",
    "    # Extract \"Abstract\" field\n",
    "    abstract_pattern = r\"Journal-ref:[^\\\\\\\\]*\\\\\\\\[\\n\\s]*(.*?)(?=\\\\\\\\)\"\n",
    "    abstract_match = re.search(abstract_pattern, record, re.DOTALL)\n",
    "    if abstract_match:\n",
    "        abstract = abstract_match.group(1)\n",
    "        abstract = abstract.replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "        info[\"Abstract\"] = abstract.strip()\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f0c15-5080-4875-9c9a-9312ee9e5ab6",
   "metadata": {},
   "source": [
    "### Testing Our Information Extraction\n",
    "\n",
    "To develop the above I created the unit tests below. Inspect the values so you agree they work :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92f08f8-aa75-44a7-8e9c-b941b7bf0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "(doc1, doc2) = docs\n",
    "\n",
    "paper_info = extract_paper_info(doc1)\n",
    "# Get the paper ID part of the \"Paper\" field\n",
    "paper_id = int(paper_info.get(\"Paper\", \"\").split(\"/\")[-1])\n",
    "assert paper_info[\"Paper\"] == \"hep-th/9612115\"\n",
    "assert paper_id == 9612115\n",
    "\n",
    "paper_info = extract_paper_info(doc2)\n",
    "# Get the paper ID part of the \"Paper\" field\n",
    "paper_id = int(paper_info.get(\"Paper\", \"\").split(\"/\")[-1])\n",
    "assert paper_info[\"Paper\"] == \"hep-th/9711029\"\n",
    "assert paper_id == 9711029"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1786f68-848a-442a-9e96-ccd70debf27a",
   "metadata": {},
   "source": [
    "### Setting Node Properties\n",
    "\n",
    "With our information extraction function tested, we are ready to loop through the abstract metadata tarball's files `G.nodes()` and assign the extract function's fields as node fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18b0860-2b80-4903-9d5b-1bc7c557d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added metadata to 27,770 nodes, 1,785 were unknown.\n"
     ]
    }
   ],
   "source": [
    "hit_count, miss_count, matches = 0, 0, 0\n",
    "all_abstracts: List[str] = []\n",
    "abstracts: Dict[int, str] = {}\n",
    "paper_ids: List[int] = []\n",
    "# Decompress the gzip content, then work through the abstract files in the tarball\n",
    "with gzip.GzipFile(fileobj=abstract_gzip_content) as f:\n",
    "    with tarfile.open(fileobj=f, mode=\"r|\") as tar:\n",
    "        for member in tar:\n",
    "            abstract_file = tar.extractfile(member)\n",
    "            if abstract_file:\n",
    "                content = abstract_file.read().decode(\"utf-8\")\n",
    "\n",
    "                paper_id = int(os.path.basename(member.name).split(\".\")[0])\n",
    "\n",
    "                # We can also parse and use those values directly or embed field-wise\n",
    "                paper_info = extract_paper_info(content)\n",
    "                if paper_info:\n",
    "                    abstract_paper_id = paper_info.get(\"Paper\", \"\").split(\"/\")[-1]\n",
    "                    if paper_id != int(abstract_paper_id):\n",
    "                        matches += 1\n",
    "                        print(f\"Paper ID {paper_id} != {abstract_paper_id}\")\n",
    "\n",
    "                    # Get the paper ID part of the \"Paper\" field\n",
    "                    if paper_id in file_to_net and file_to_net[paper_id] in G:\n",
    "                        for field, value in paper_info.items():\n",
    "                            G.nodes[file_to_net[paper_id]][field] = value\n",
    "\n",
    "                        abstracts[paper_id] = content\n",
    "                        all_abstracts.append(content)\n",
    "                        paper_ids.append(paper_id)\n",
    "\n",
    "                        hit_count += 1\n",
    "\n",
    "                    else:\n",
    "                        # Add isolated nodes if paper_id isn't in G\n",
    "                        miss_count += 1\n",
    "                        # We could do this for some use cases to create isolated nodes. Not all graphs are connected. See Part 2, Network Science.\n",
    "                        # G.add_node(file_to_net[paper_id], **paper_info)\n",
    "\n",
    "# Now `G` is a property graph representing the \"High-energy physics theory citation network\" dataset\n",
    "print(f\"Added metadata to {hit_count:,} nodes, {miss_count:,} were unknown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7767a17-0955-4a8f-a34e-9996fcb54b90",
   "metadata": {},
   "source": [
    "## Temporal Networks\n",
    "\n",
    "Our citation graph is a temporal network. Temporal networks have a determined sequence in which nodes are added to the graph - just as real networks evolve. Network science and graph machine learning for temporal networks that don't take time into account can result in incorrect analyses and inaccurate machine learning inference.\n",
    "\n",
    "<center><img src=\"images/Temporal-vs-static-networks-A-The-sequence-of-contacts-among-three-nodes-capturing_W640.jpg\" width=\"800px\" /></center>\n",
    "<center>Image source: <a href=\"https://www.researchgate.net/publication/305492361_The_fundamental_advantages_of_temporal_networks\">The fundamental advantages of temporal networks, Li et al., 2016</a></center>\n",
    "\n",
    "### Downloading Publishing Dates\n",
    "\n",
    "The timestamps are available at [https://snap.stanford.edu/data/cit-HepTh-dates.txt.gz](https://snap.stanford.edu/data/cit-HepTh-dates.txt.gz) and are downloaded to `data/cit-HepTh-dates.txt.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35f49a5-d300-4c10-8cef-ccbd664257fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing paper dates file data/cit-HepTh-dates.txt.gz\n"
     ]
    }
   ],
   "source": [
    "# Download and load edges (citations) from `cit-HepTh.txt.gz`\n",
    "dates_path = \"data/cit-HepTh-dates.txt.gz\"\n",
    "date_gzip_content = None\n",
    "\n",
    "if os.path.exists(dates_path):\n",
    "    print(f\"Using existing paper dates file {dates_path}\")\n",
    "    date_gzip_content = open(dates_path, \"rb\")\n",
    "else:\n",
    "    print(\"Downloading paper publishing dates ...\")\n",
    "    date_response = requests.get(f\"https://snap.stanford.edu/{dates_path}\")\n",
    "    date_gzip_content = io.BytesIO(date_response.content)\n",
    "\n",
    "    with open(dates_path, \"wb\") as f:\n",
    "        f.write(date_response.content)\n",
    "        print(\"Wrote downloaded publishing dates file to {dates_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc8390-c714-4c75-b702-5f3c243e1d0d",
   "metadata": {},
   "source": [
    "### Adding a Temporal Property\n",
    "\n",
    "Publishing dates go under the `Published` node property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acaca8e5-e0c1-4fbc-ba9a-a514218acccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding publising dates ...\n"
     ]
    }
   ],
   "source": [
    "# Decompress the gzip content and add a \"published\" date property to our nodes\n",
    "print(\"Adding publising dates ...\")\n",
    "with gzip.GzipFile(fileobj=date_gzip_content) as f:\n",
    "    for line in f:\n",
    "        line = line.decode(\"utf-8\")\n",
    "        # Ignore lines that start with '#'\n",
    "        if not line.startswith(\"#\"):\n",
    "            paper_id, iso_date = line.strip().split(\"\\t\")\n",
    "\n",
    "            # The edge list makes the paper ID an int, stripping 0001001 to 1001, for example\n",
    "            paper_id = int(paper_id)\n",
    "\n",
    "            if paper_id in file_to_net and file_to_net[paper_id] in G:\n",
    "                # Add a UTC timestamp for the data\n",
    "                G.nodes[file_to_net[paper_id]][\"Published\"] = calendar.timegm(\n",
    "                    date.fromisoformat(iso_date).timetuple()\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a45ded-092d-49e7-bcbd-55018997b7e7",
   "metadata": {},
   "source": [
    "### Test our Network Build\n",
    "\n",
    "Let's make sure everything built as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2a6d03a-4bbe-4997-b3fd-6ee1f728c927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"file_id\": 1001,\n",
      "    \"sequential_id\": 0,\n",
      "    \"Paper\": \"hep-th/0001001\",\n",
      "    \"From\": \"Paul S. Aspinwall\",\n",
      "    \"Date\": \"Sat, 1 Jan 2000 00:02:31 GMT\",\n",
      "    \"Title\": \"Compactification, Geometry and Duality: N=2\",\n",
      "    \"Authors\": \"Paul S. Aspinwall\",\n",
      "    \"Comments\": \"82 pages, 8 figures, LaTeX2e, TASI99, refs added and some typos fixed\",\n",
      "    \"Report-no\": \"DUKE-CGTP-00-01\",\n",
      "    \"Published\": 946684800\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# What is the first node?\n",
    "test_node = G.nodes[0]\n",
    "\n",
    "assert test_node[\"sequential_id\"] == 0\n",
    "assert test_node[\"file_id\"] == 1001\n",
    "\n",
    "print(json.dumps(test_node, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5228d39-a3d1-40ef-ab76-f1bf99b79c37",
   "metadata": {},
   "source": [
    "## Abstract Embeddings\n",
    "\n",
    "In addition to parsing the data, we will embed the entire record. First we create a utility to embed string columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0043881c-c4d7-4357-b284-7e65ffb2063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa37dfea-c8da-429d-83df-011c3fbc755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01bb1116-6b21-45f7-94f2-49fe6af97658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_paper_info(\n",
    "    records: Union[str, List[str]], convert_to_tensor=True\n",
    ") -> Union[np.ndarray, Tensor]:\n",
    "    if records and isinstance(records, str):\n",
    "        records = [records]\n",
    "    return paraphrase_model.encode(records, convert_to_tensor=convert_to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a38e4d-40f6-4484-be82-743f496cfdf8",
   "metadata": {},
   "source": [
    "Then we embed all the nodes' metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0734266-b939-4438-8711-f675bfa93479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the abstracts for GNN features. Embedding is a generic approach for retrieval as well.\n",
    "# Note: NetworkX can't save lists in GEXF format, so we'll JSONize the list & save the embeddings separately.\n",
    "embedded_abstracts: np.ndarray = None\n",
    "if os.path.exists(\"data/embedded_abstracts.npy\"):\n",
    "    embedded_abstracts = np.load(\"data/embedded_abstracts.npy\")\n",
    "else:\n",
    "    embedded_abstracts = embed_paper_info(all_abstracts, convert_to_tensor=False)\n",
    "    np.save(\"data/embedded_abstracts.npy\", embedded_abstracts)\n",
    "\n",
    "node_embedding_dict: Dict[int, List[float]] = {}\n",
    "if os.path.exists(\"data/node_embedding_dict.json.gz\"):\n",
    "    node_embedding_dict = json.load(\n",
    "        gzip.GzipFile(\"data/node_embedding_dict.json.gz\", \"r\"),\n",
    "        # encoding=\"utf-8\",\n",
    "    )\n",
    "else:\n",
    "    for paper_id, emb in zip(paper_ids, embedded_abstracts):\n",
    "        assert emb.shape == (384,)\n",
    "\n",
    "        # Gephi assumes a list of floats is a time series, so we need to convert to a string\n",
    "        emb_list = emb.tolist()\n",
    "        G.nodes[file_to_net[paper_id]][\"Embedding-JSON\"] = json.dumps(emb_list)\n",
    "\n",
    "        node_embedding_dict[paper_id] = emb_list\n",
    "\n",
    "# Write the mapping from paper ID to embedding to JSON.\n",
    "# Note: All JSON keys are strings. We will have to int(key) to read the data back.\n",
    "json.dump(\n",
    "    node_embedding_dict,\n",
    "    io.TextIOWrapper(\n",
    "        gzip.GzipFile(\"data/node_embedding_dict.json.gz\", \"w\"),\n",
    "        encoding=\"utf-8\",\n",
    "    ),\n",
    "    indent=4,\n",
    "    sort_keys=True,\n",
    ")\n",
    "\n",
    "# Write the entire network using GEXF format - the date has to be in UTC format for this to work.\n",
    "nx.write_gexf(G, path=\"data/physics_embeddings.gexf\", prettyprint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a32b3-319e-43ac-ab12-a4d906018c2d",
   "metadata": {},
   "source": [
    "# Label Making and K-Nearest-Neighbors (KNN) Graph Building\n",
    "\n",
    "Now we are going to build a pandas `DataFrame` or `pd.DataFrame` of our nodes so we can create clean labels for our journals. These will serve as labels for our machine-learning tasks using this network.\n",
    "\n",
    "In this section, we will also demonstrate another method of building a network - K-nearest-neighbors construction.\n",
    "\n",
    "## Building a Node `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65ea0cd4-6b8d-40b6-a3d9-af30157e999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequential_id</th>\n",
       "      <th>Paper</th>\n",
       "      <th>From</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Report-no</th>\n",
       "      <th>Published</th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>hep-th/0001001</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>Sat, 1 Jan 2000 00:02:31 GMT</td>\n",
       "      <td>Compactification, Geometry and Duality: N=2</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td>82 pages, 8 figures, LaTeX2e, TASI99, refs add...</td>\n",
       "      <td>DUKE-CGTP-00-01</td>\n",
       "      <td>946684800.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9304045</td>\n",
       "      <td>1</td>\n",
       "      <td>hep-th/9304045</td>\n",
       "      <td></td>\n",
       "      <td>Sun, 11 Apr 93 12:29:30 -0500</td>\n",
       "      <td>Generalized Calabi-Yau Manifolds and the Mirro...</td>\n",
       "      <td>P. Candelas, E. Derrick and L. Parkes</td>\n",
       "      <td>39 pages, plain TeX</td>\n",
       "      <td>CERN-TH.6831/93, UTTG-24-92</td>\n",
       "      <td></td>\n",
       "      <td>Nucl.Phys. B407 (1993) 115-154</td>\n",
       "      <td>We describe the mirror of the Z orbifold as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9308122</td>\n",
       "      <td>2</td>\n",
       "      <td>hep-th/9308122</td>\n",
       "      <td></td>\n",
       "      <td>Thu, 26 Aug 93 14:09:47 SET</td>\n",
       "      <td>Mirror Symmetry, Mirror Map and Applications t...</td>\n",
       "      <td>S. Hosono, A. Klemm, S. Theisen</td>\n",
       "      <td>59 pages. Some changes in the references, a fe...</td>\n",
       "      <td>HUTMP-93/0801, LMU-TPW-93-22</td>\n",
       "      <td></td>\n",
       "      <td>Commun.Math.Phys. 167 (1995) 301-350</td>\n",
       "      <td>Mirror Symmetry, Picard-Fuchs equations and in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9309097</td>\n",
       "      <td>3</td>\n",
       "      <td>hep-th/9309097</td>\n",
       "      <td></td>\n",
       "      <td>Fri, 17 Sep 93 17:18:41 EDT</td>\n",
       "      <td>Calabi-Yau Moduli Space, Mirror Manifolds and ...</td>\n",
       "      <td>P.S. Aspinwall, B.R. Greene and D.R. Morrison</td>\n",
       "      <td>74 pages (with 20 figures)</td>\n",
       "      <td>IASSNS-HEP-93/38, CNLS-93/1236</td>\n",
       "      <td></td>\n",
       "      <td>Nucl.Phys. B416 (1994) 414-480</td>\n",
       "      <td>We analyze the moduli spaces of Calabi-Yau thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9311042</td>\n",
       "      <td>4</td>\n",
       "      <td>hep-th/9311042</td>\n",
       "      <td></td>\n",
       "      <td>Sun, 7 Nov 93 23:00:47 EST</td>\n",
       "      <td>Measuring Small Distances in N=2 Sigma Models</td>\n",
       "      <td>Paul S. Aspinwall, Brian R. Greene, and David ...</td>\n",
       "      <td>62 pp. with 6 figs., LaTeX and epsf.tex</td>\n",
       "      <td>IASSNS-HEP-93/49</td>\n",
       "      <td></td>\n",
       "      <td>Nucl.Phys. B420 (1994) 184-242</td>\n",
       "      <td>We analyze global aspects of the moduli space ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node  file_id  sequential_id           Paper               From  \\\n",
       "0     0     1001              0  hep-th/0001001  Paul S. Aspinwall   \n",
       "1     1  9304045              1  hep-th/9304045                      \n",
       "2     2  9308122              2  hep-th/9308122                      \n",
       "3     3  9309097              3  hep-th/9309097                      \n",
       "4     4  9311042              4  hep-th/9311042                      \n",
       "\n",
       "                            Date  \\\n",
       "0   Sat, 1 Jan 2000 00:02:31 GMT   \n",
       "1  Sun, 11 Apr 93 12:29:30 -0500   \n",
       "2    Thu, 26 Aug 93 14:09:47 SET   \n",
       "3    Fri, 17 Sep 93 17:18:41 EDT   \n",
       "4     Sun, 7 Nov 93 23:00:47 EST   \n",
       "\n",
       "                                               Title  \\\n",
       "0        Compactification, Geometry and Duality: N=2   \n",
       "1  Generalized Calabi-Yau Manifolds and the Mirro...   \n",
       "2  Mirror Symmetry, Mirror Map and Applications t...   \n",
       "3  Calabi-Yau Moduli Space, Mirror Manifolds and ...   \n",
       "4      Measuring Small Distances in N=2 Sigma Models   \n",
       "\n",
       "                                             Authors  \\\n",
       "0                                  Paul S. Aspinwall   \n",
       "1              P. Candelas, E. Derrick and L. Parkes   \n",
       "2                    S. Hosono, A. Klemm, S. Theisen   \n",
       "3      P.S. Aspinwall, B.R. Greene and D.R. Morrison   \n",
       "4  Paul S. Aspinwall, Brian R. Greene, and David ...   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  82 pages, 8 figures, LaTeX2e, TASI99, refs add...   \n",
       "1                                39 pages, plain TeX   \n",
       "2  59 pages. Some changes in the references, a fe...   \n",
       "3                         74 pages (with 20 figures)   \n",
       "4            62 pp. with 6 figs., LaTeX and epsf.tex   \n",
       "\n",
       "                        Report-no    Published  \\\n",
       "0                 DUKE-CGTP-00-01  946684800.0   \n",
       "1     CERN-TH.6831/93, UTTG-24-92                \n",
       "2    HUTMP-93/0801, LMU-TPW-93-22                \n",
       "3  IASSNS-HEP-93/38, CNLS-93/1236                \n",
       "4                IASSNS-HEP-93/49                \n",
       "\n",
       "                            Journal-ref  \\\n",
       "0                                         \n",
       "1        Nucl.Phys. B407 (1993) 115-154   \n",
       "2  Commun.Math.Phys. 167 (1995) 301-350   \n",
       "3        Nucl.Phys. B416 (1994) 414-480   \n",
       "4        Nucl.Phys. B420 (1994) 184-242   \n",
       "\n",
       "                                            Abstract  \n",
       "0                                                     \n",
       "1  We describe the mirror of the Z orbifold as a ...  \n",
       "2  Mirror Symmetry, Picard-Fuchs equations and in...  \n",
       "3  We analyze the moduli spaces of Calabi-Yau thr...  \n",
       "4  We analyze global aspects of the moduli space ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract nodes and their attributes into a list of dictionaries\n",
    "node_data = [{**{\"node\": node}, **attr} for node, attr in G.nodes(data=True)]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "node_df = pd.DataFrame(node_data)\n",
    "\n",
    "# Cleanup\n",
    "node_df.fillna(\"\", inplace=True)\n",
    "\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83edc4-87f5-483b-874b-e4715569dbb0",
   "metadata": {},
   "source": [
    "## Clustering `Journal-ref`\n",
    "\n",
    "Taking a look at the field representing the journal a paper appeared in, we have a problem if we want to use this field as a label for a categorical classification... this is a fuzzy string problem, not a regular expression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d92b9e53-2e5b-4896-998f-5661722acb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18147          Nucl.Phys. B388 (1992) 539-569\n",
       "12226                                        \n",
       "19902          Phys.Lett. B532 (2002) 297-304\n",
       "25669                                        \n",
       "7449             Phys.Lett. A212 (1996) 22-28\n",
       "13628         AIP Conf.Proc. 453 (1998) 49-52\n",
       "22455                                        \n",
       "12328             Nonlinearity 13 (2000) 2163\n",
       "8844       Int.J.Mod.Phys. A17 (2002) 625-642\n",
       "6681     Int.J.Mod.Phys. A11 (1996) 3049-3096\n",
       "Name: Journal-ref, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df[\"Journal-ref\"].sample(n=10).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ab1d4-98e8-458e-80eb-1226342d7a6d",
   "metadata": {},
   "source": [
    "### Embedding `Title`, `Abstract` and `Journal-ref`\n",
    "\n",
    "That's ok! We will embed the `Journal-ref` field and cluster it to arrive at our class labels for each journal. This will give us a head start on presenting network construction using K-Nearest-Neighbors in the next section :)\n",
    "\n",
    "#### Simplify `Journal-ref` for Clustering\n",
    "\n",
    "What if we remove all the dates entirely? This should help us find titles :) While I am demonstrating vector operations, we might just use a Bag-of-Words model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7d78186-7b6a-47f3-b87f-3a98918b8d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        \n",
       "1              Nucl.Phys.\n",
       "2        Commun.Math.Phys\n",
       "3              Nucl.Phys.\n",
       "4              Nucl.Phys.\n",
       "               ...       \n",
       "27765    Int.J.Theor.Phys\n",
       "27766           J.Phys.AL\n",
       "27767           Phys.Rev.\n",
       "27768          Nucl.Phys.\n",
       "27769                    \n",
       "Name: Journal-ref-Letters, Length: 27770, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all non-text characters from Journal-ref to make it cluster better\n",
    "node_df[\"Journal-ref-Letters\"] = node_df[\"Journal-ref\"].str.replace(r\"[^a-zA-Z.]\", \"\", regex=True).str.strip().str[:-1]\n",
    "node_df[\"Journal-ref-Letters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38c5e31a-855a-4b3c-af6c-1b570eb2c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cache_column(input_col: str, model_name: str, model: SentenceTransformer, df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Given an input column, model name, SentenceTransformer model and a pd.DataFrame, produce an embedding.\"\"\"\n",
    "\n",
    "    base_path = \"data/embedded_journals\"\n",
    "    file_name = f\"{input_col}-{model_name}-Embedding.npy\"\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    \n",
    "    embedding: np.ndarray = None\n",
    "    if os.path.exists(file_path):\n",
    "        embedding = np.load(file_path)\n",
    "        print(f\"Cachce hit for {file_name}\")\n",
    "    else:\n",
    "        embedding = model.encode(df[column].tolist())\n",
    "        np.save(file_path, embedding)\n",
    "        print(f\"Cache miss for {file_name}, saved.\")\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf4e54-40a5-4dc9-b77b-86e4ff42d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Embed the relevant text columns Journal-ref and cluster them to produce journal class labels.\n",
    "paraphrase_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "all_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed these columns\n",
    "paraphrase_embeddings: Dict[str, np.ndarray] = {}\n",
    "all_embeddings: Dict[str, np.ndarray] = {}\n",
    "\n",
    "# Generate embeddings, but do cache\n",
    "for column in [\"Title\", \"Abstract\", \"Journal-ref\", \"Journal-ref-Letters\"]:\n",
    "\n",
    "    # Paraphrase model\n",
    "    paraphrase_embeddings[column] = embed_cache_column(column, \"Paraphrase\", paraphrase_model, node_df)\n",
    "    node_df[f\"{column}-Paraphrase-Embedding\"] = paraphrase_embeddings[column].tolist()\n",
    "    print(f\"Embedded {column} using paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "    # All model\n",
    "    all_embeddings[column] = embed_column(column, \"All\", all_model, node_df)\n",
    "    node_df[f\"{column}-All-Embedding\"] = all_embeddings[column].tolist()   \n",
    "    print(f\"Embedded {column} in all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27846474-5bb9-4617-b223-d69074c81673",
   "metadata": {},
   "source": [
    "#### Assign Embeddings back to `node_df` `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "52417cab-bb35-4667-90ff-4d605c920025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Journal-ref-Letters</th>\n",
       "      <th>Journal-ref-Letters-All-Embedding</th>\n",
       "      <th>Journal-ref-Letters-Paraphrase-Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21117</th>\n",
       "      <td>Nucl.Phys. B639 (2002) 182-202</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>[-0.07679721713066101, -0.04238727316260338, -...</td>\n",
       "      <td>[-0.7856213450431824, 0.3381310999393463, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Phys.Lett. B469 (1999) 37-45</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>[-0.04930078238248825, -0.029769131913781166, ...</td>\n",
       "      <td>[-0.32123279571533203, -0.2982199788093567, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26739</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>Nucl.Phys.Proc.Suppl. 56B (1997) 61-69</td>\n",
       "      <td>Nucl.Phys.Proc.Suppl.</td>\n",
       "      <td>[-0.11537209898233414, -0.07562218606472015, -...</td>\n",
       "      <td>[-0.8103715777397156, 0.24846340715885162, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>Nucl. Phys. B454 (1995) 561</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>[-0.07679721713066101, -0.04238727316260338, -...</td>\n",
       "      <td>[-0.7856213450431824, 0.3381310999393463, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22648</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>Lect.Notes Phys. 541 (2000) 79-100</td>\n",
       "      <td>Lect.NotesPhys</td>\n",
       "      <td>[-0.07537288218736649, 0.009111492894589901, 0...</td>\n",
       "      <td>[-0.3462257385253906, 0.5426188111305237, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11435</th>\n",
       "      <td>Nucl.Phys. B384 (1992) 381-410</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>[-0.07679721713066101, -0.04238727316260338, -...</td>\n",
       "      <td>[-0.7856213450431824, 0.3381310999393463, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>Phys.Rev. D62 (2000) 027701</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>[-0.06749877333641052, -0.0029817521572113037,...</td>\n",
       "      <td>[-0.5587078928947449, -0.15173283219337463, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>Nucl. Phys. B446 (1995) 16</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>[-0.07679721713066101, -0.04238727316260338, -...</td>\n",
       "      <td>[-0.7856213450431824, 0.3381310999393463, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15646</th>\n",
       "      <td>Phys.Rev. D64 (2001) 025014</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>[-0.06749877333641052, -0.0029817521572113037,...</td>\n",
       "      <td>[-0.5587078928947449, -0.15173283219337463, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>JHEP 0003 (2000) 023</td>\n",
       "      <td>JHE</td>\n",
       "      <td>[-0.06578471511602402, 0.04429247975349426, 0....</td>\n",
       "      <td>[-0.12954038381576538, 0.47970205545425415, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15175</th>\n",
       "      <td>Prog.Theor.Phys.Suppl. 135 (1999) 94-108</td>\n",
       "      <td>Prog.Theor.Phys.Suppl</td>\n",
       "      <td>[-0.10335496813058853, -0.01975909247994423, -...</td>\n",
       "      <td>[-0.44247862696647644, 0.0629902333021164, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Nucl.Phys. B545 (1999) 543-575</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>[-0.07679721713066101, -0.04238727316260338, -...</td>\n",
       "      <td>[-0.7856213450431824, 0.3381310999393463, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22446</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>Lett.Math.Phys. 40 (1997) 17-30</td>\n",
       "      <td>Lett.Math.Phys</td>\n",
       "      <td>[-0.05300202593207359, -0.01920085959136486, 0...</td>\n",
       "      <td>[-0.39051583409309387, 0.04808436334133148, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26349</th>\n",
       "      <td>Nucl.Phys. B496 (1997) 465-485</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>[-0.07679721713066101, -0.04238727316260338, -...</td>\n",
       "      <td>[-0.7856213450431824, 0.3381310999393463, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>Int.J.Mod.Phys. A12 (1997) 4357-4368</td>\n",
       "      <td>Int.J.Mod.Phys.</td>\n",
       "      <td>[-0.10542818903923035, 0.00243875733576715, -0...</td>\n",
       "      <td>[-0.19118404388427734, -0.21069897711277008, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24158</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24808</th>\n",
       "      <td>Lett. Math. Phys. 33 (1995) 49-59</td>\n",
       "      <td>Lett.Math.Phys</td>\n",
       "      <td>[-0.05300202593207359, -0.01920085959136486, 0...</td>\n",
       "      <td>[-0.39051583409309387, 0.04808436334133148, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>J.Math.Phys. 35 (1994) 5844-5849</td>\n",
       "      <td>J.Math.Phys</td>\n",
       "      <td>[-0.08066173642873764, -0.0405711866915226, -0...</td>\n",
       "      <td>[-0.5401061177253723, -0.05109339579939842, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7467</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23319</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22400</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19121</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.1188383623957634, 0.04829862341284752, -0....</td>\n",
       "      <td>[0.15472710132598877, 0.18004412949085236, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13308</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21079</th>\n",
       "      <td>JHEP 0209 (2002) 012</td>\n",
       "      <td>JHE</td>\n",
       "      <td>[-0.06578469276428223, 0.044292472302913666, 0...</td>\n",
       "      <td>[-0.12954093515872955, 0.4797024428844452, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>Phys. Lett. B294 (1992) 331-336</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>[-0.04930078238248825, -0.029769131913781166, ...</td>\n",
       "      <td>[-0.32123279571533203, -0.2982199788093567, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14561</th>\n",
       "      <td>Phys.Lett. B523 (2001) 185-190</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>[-0.04930078238248825, -0.029769131913781166, ...</td>\n",
       "      <td>[-0.32123279571533203, -0.2982199788093567, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[-0.11883842200040817, 0.04829862713813782, -0...</td>\n",
       "      <td>[0.15472735464572906, 0.18004417419433594, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Journal-ref    Journal-ref-Letters  \\\n",
       "21117            Nucl.Phys. B639 (2002) 182-202             Nucl.Phys.   \n",
       "5568               Phys.Lett. B469 (1999) 37-45             Phys.Lett.   \n",
       "26739                                                                    \n",
       "5196     Nucl.Phys.Proc.Suppl. 56B (1997) 61-69  Nucl.Phys.Proc.Suppl.   \n",
       "5405                Nucl. Phys. B454 (1995) 561             Nucl.Phys.   \n",
       "22648                                                                    \n",
       "7836         Lect.Notes Phys. 541 (2000) 79-100         Lect.NotesPhys   \n",
       "11435            Nucl.Phys. B384 (1992) 381-410             Nucl.Phys.   \n",
       "3521                Phys.Rev. D62 (2000) 027701              Phys.Rev.   \n",
       "7600                 Nucl. Phys. B446 (1995) 16             Nucl.Phys.   \n",
       "15646               Phys.Rev. D64 (2001) 025014              Phys.Rev.   \n",
       "6414                       JHEP 0003 (2000) 023                    JHE   \n",
       "15175  Prog.Theor.Phys.Suppl. 135 (1999) 94-108  Prog.Theor.Phys.Suppl   \n",
       "2201             Nucl.Phys. B545 (1999) 543-575             Nucl.Phys.   \n",
       "22446                                                                    \n",
       "8720            Lett.Math.Phys. 40 (1997) 17-30         Lett.Math.Phys   \n",
       "26349            Nucl.Phys. B496 (1997) 465-485             Nucl.Phys.   \n",
       "9012       Int.J.Mod.Phys. A12 (1997) 4357-4368        Int.J.Mod.Phys.   \n",
       "24158                                                                    \n",
       "24808         Lett. Math. Phys. 33 (1995) 49-59         Lett.Math.Phys   \n",
       "4752           J.Math.Phys. 35 (1994) 5844-5849            J.Math.Phys   \n",
       "7467                                                                     \n",
       "23319                                                                    \n",
       "22400                                                                    \n",
       "19121                                                                    \n",
       "13308                                                                    \n",
       "21079                      JHEP 0209 (2002) 012                    JHE   \n",
       "4056            Phys. Lett. B294 (1992) 331-336             Phys.Lett.   \n",
       "14561            Phys.Lett. B523 (2001) 185-190             Phys.Lett.   \n",
       "3131                                                                     \n",
       "\n",
       "                       Journal-ref-Letters-All-Embedding  \\\n",
       "21117  [-0.07679721713066101, -0.04238727316260338, -...   \n",
       "5568   [-0.04930078238248825, -0.029769131913781166, ...   \n",
       "26739  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "5196   [-0.11537209898233414, -0.07562218606472015, -...   \n",
       "5405   [-0.07679721713066101, -0.04238727316260338, -...   \n",
       "22648  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "7836   [-0.07537288218736649, 0.009111492894589901, 0...   \n",
       "11435  [-0.07679721713066101, -0.04238727316260338, -...   \n",
       "3521   [-0.06749877333641052, -0.0029817521572113037,...   \n",
       "7600   [-0.07679721713066101, -0.04238727316260338, -...   \n",
       "15646  [-0.06749877333641052, -0.0029817521572113037,...   \n",
       "6414   [-0.06578471511602402, 0.04429247975349426, 0....   \n",
       "15175  [-0.10335496813058853, -0.01975909247994423, -...   \n",
       "2201   [-0.07679721713066101, -0.04238727316260338, -...   \n",
       "22446  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "8720   [-0.05300202593207359, -0.01920085959136486, 0...   \n",
       "26349  [-0.07679721713066101, -0.04238727316260338, -...   \n",
       "9012   [-0.10542818903923035, 0.00243875733576715, -0...   \n",
       "24158  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "24808  [-0.05300202593207359, -0.01920085959136486, 0...   \n",
       "4752   [-0.08066173642873764, -0.0405711866915226, -0...   \n",
       "7467   [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "23319  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "22400  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "19121  [-0.1188383623957634, 0.04829862341284752, -0....   \n",
       "13308  [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "21079  [-0.06578469276428223, 0.044292472302913666, 0...   \n",
       "4056   [-0.04930078238248825, -0.029769131913781166, ...   \n",
       "14561  [-0.04930078238248825, -0.029769131913781166, ...   \n",
       "3131   [-0.11883842200040817, 0.04829862713813782, -0...   \n",
       "\n",
       "                Journal-ref-Letters-Paraphrase-Embedding  \n",
       "21117  [-0.7856213450431824, 0.3381310999393463, 0.08...  \n",
       "5568   [-0.32123279571533203, -0.2982199788093567, 0....  \n",
       "26739  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "5196   [-0.8103715777397156, 0.24846340715885162, -0....  \n",
       "5405   [-0.7856213450431824, 0.3381310999393463, 0.08...  \n",
       "22648  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "7836   [-0.3462257385253906, 0.5426188111305237, -0.6...  \n",
       "11435  [-0.7856213450431824, 0.3381310999393463, 0.08...  \n",
       "3521   [-0.5587078928947449, -0.15173283219337463, 0....  \n",
       "7600   [-0.7856213450431824, 0.3381310999393463, 0.08...  \n",
       "15646  [-0.5587078928947449, -0.15173283219337463, 0....  \n",
       "6414   [-0.12954038381576538, 0.47970205545425415, -0...  \n",
       "15175  [-0.44247862696647644, 0.0629902333021164, 0.0...  \n",
       "2201   [-0.7856213450431824, 0.3381310999393463, 0.08...  \n",
       "22446  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "8720   [-0.39051583409309387, 0.04808436334133148, 0....  \n",
       "26349  [-0.7856213450431824, 0.3381310999393463, 0.08...  \n",
       "9012   [-0.19118404388427734, -0.21069897711277008, -...  \n",
       "24158  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "24808  [-0.39051583409309387, 0.04808436334133148, 0....  \n",
       "4752   [-0.5401061177253723, -0.05109339579939842, 0....  \n",
       "7467   [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "23319  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "22400  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "19121  [0.15472710132598877, 0.18004412949085236, 0.0...  \n",
       "13308  [0.15472735464572906, 0.18004417419433594, 0.0...  \n",
       "21079  [-0.12954093515872955, 0.4797024428844452, -0....  \n",
       "4056   [-0.32123279571533203, -0.2982199788093567, 0....  \n",
       "14561  [-0.32123279571533203, -0.2982199788093567, 0....  \n",
       "3131   [0.15472735464572906, 0.18004417419433594, 0.0...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's go with Journal-ref-Letters-Embedding below, less variance\n",
    "node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-Letters-All-Embedding\", \"Journal-ref-Letters-Paraphrase-Embedding\"]].sample(30).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622cf8-0814-43fe-86a6-b1680754610d",
   "metadata": {},
   "source": [
    "### Clustering `Journal-ref-Letters-Embedding`\n",
    "\n",
    "Now we will use [UMAP](https://umap-learn.readthedocs.io/en/latest/) via the [umap-learn](https://umap-learn.readthedocs.io/en/latest/basic_usage.html) PyPi library to reduce our data to 2 dimensions and then [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN) [which workds with 2D data and infers circles aroud centrioids] via [scikit-learn]() to cluster it into journal names. Our final step is to nominate a real journal name for each cluster, which we will do manually as this course is about graph ML and this is NLP :)\n",
    "\n",
    "Note that while normally you need to [standardize data](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#standardscaler) to give it a normal distribution with something like [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), you do not need to do this when sentence encoding data with a sentence transformer as we have done.\n",
    "\n",
    "#### KMeans - Did Not Work :)\n",
    "\n",
    "KMeans didn't work, which is probably because I didn't know how to tune it effectively, but DBSCAN is fairly automatic and produced good clusters, so I used that. If you think about it though, KMeans starts with random centroids... and that is why it is splitting journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0920893c-b620-4bac-bffa-32c419d1b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(\n",
    "    n_clusters=15,\n",
    "    init=\"k-means++\",\n",
    "    max_iter=200,\n",
    ")\n",
    "\n",
    "# Apply to both embeddings\n",
    "paraphrase_class_scores = km.fit_transform(node_df[\"Journal-ref-Letters-Paraphrase-Embedding\"].tolist())\n",
    "paraphrase_classes = np.argmax(paraphrase_class_scores, axis=1)\n",
    "node_df[\"Journal-ref-Letters-Paraphrase-KMeans\"] = paraphrase_classes.tolist()\n",
    "\n",
    "all_class_scores = km.fit_transform(node_df[\"Journal-ref-Letters-All-Embedding\"].tolist())\n",
    "all_classes = np.argmax(all_class_scores, axis=1)\n",
    "node_df[\"Journal-ref-Letters-All-KMeans\"] = all_classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a5a83c5-dbbe-4ccf-b81d-07a57e33d5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 0,  1,  3,  4,  6,  7, 11]),\n",
       "  array([    3,     4,  1100,    21,    16,  3516, 23110])),\n",
       " (27770,))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(paraphrase_classes, return_counts=True), paraphrase_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b814ead0-4090-420a-8956-24d9b9bad9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 11, 14]),\n",
       "  array([   49, 16825,   257,   938,    33,  1957,  7564,    15,   121,\n",
       "             7,     4])),\n",
       " (27770,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_classes, return_counts=True), all_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "78a52bee-c522-4553-9529-e36c91fc3c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Journal-ref-Letters</th>\n",
       "      <th>Journal-ref-Letters-Paraphrase-KMeans</th>\n",
       "      <th>Journal-ref-Letters-All-KMeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6846</th>\n",
       "      <td>Phys.Rev. D59 (1999) 065008</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>Phys.Rev. D60 (1999) 041901</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19721</th>\n",
       "      <td>Fortsch.Phys. 50 (2002) 825-830</td>\n",
       "      <td>Fortsch.Phys</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8793</th>\n",
       "      <td>Phys.Rev. D59 (1999) 084011</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19846</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23769</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14039</th>\n",
       "      <td>J.Geom.Phys. 19 (1996) 18-30</td>\n",
       "      <td>J.Geom.Phys</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>Nucl.Phys. B528 (1998) 197-217</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17453</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25780</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27304</th>\n",
       "      <td>Mod.Phys.Lett. A14 (1999) 1123-1131</td>\n",
       "      <td>Mod.Phys.Lett.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Phys.Lett. B296 (1992) 51-57</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17751</th>\n",
       "      <td>Nucl.Phys. B614 (2001) 330-366</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>Phys.Lett. B489 (2000) 383-389</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>Nucl.Phys. B604 (2001) 367-390</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7226</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16908</th>\n",
       "      <td>Nuovo Cim. B114 (1999) 1023-1028</td>\n",
       "      <td>NuovoCim.</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Nucl.Phys. B545 (1999) 340-370</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870</th>\n",
       "      <td>Commun.Math.Phys. 213 (2000) 523-538</td>\n",
       "      <td>Commun.Math.Phys</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12100</th>\n",
       "      <td>Phys.Lett. B353 (1995) 64-69</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15848</th>\n",
       "      <td>Phys.Rev.Lett. 83 (1999) 5596</td>\n",
       "      <td>Phys.Rev.Lett</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26867</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>Nucl.Phys. B416 (1994) 205-226</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12407</th>\n",
       "      <td>Commun.Math.Phys. 209 (2000) 757-783</td>\n",
       "      <td>Commun.Math.Phys</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24798</th>\n",
       "      <td>Mod. Phys. Lett. A9 (1994) 557-568</td>\n",
       "      <td>Mod.Phys.Lett.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Journal-ref Journal-ref-Letters  \\\n",
       "6846            Phys.Rev. D59 (1999) 065008           Phys.Rev.   \n",
       "3328            Phys.Rev. D60 (1999) 041901           Phys.Rev.   \n",
       "19721       Fortsch.Phys. 50 (2002) 825-830        Fortsch.Phys   \n",
       "8793            Phys.Rev. D59 (1999) 084011           Phys.Rev.   \n",
       "19846                                                             \n",
       "23769                                                             \n",
       "14039          J.Geom.Phys. 19 (1996) 18-30         J.Geom.Phys   \n",
       "3208         Nucl.Phys. B528 (1998) 197-217          Nucl.Phys.   \n",
       "17453                                                             \n",
       "25780                                                             \n",
       "27304   Mod.Phys.Lett. A14 (1999) 1123-1131      Mod.Phys.Lett.   \n",
       "5378                                                              \n",
       "14325                                                             \n",
       "111            Phys.Lett. B296 (1992) 51-57          Phys.Lett.   \n",
       "10513                                                             \n",
       "17751        Nucl.Phys. B614 (2001) 330-366          Nucl.Phys.   \n",
       "12610        Phys.Lett. B489 (2000) 383-389          Phys.Lett.   \n",
       "13084        Nucl.Phys. B604 (2001) 367-390          Nucl.Phys.   \n",
       "7226                                                              \n",
       "16908      Nuovo Cim. B114 (1999) 1023-1028           NuovoCim.   \n",
       "1070         Nucl.Phys. B545 (1999) 340-370          Nucl.Phys.   \n",
       "11870  Commun.Math.Phys. 213 (2000) 523-538    Commun.Math.Phys   \n",
       "12100          Phys.Lett. B353 (1995) 64-69          Phys.Lett.   \n",
       "9909                                                              \n",
       "6363                                                              \n",
       "15848         Phys.Rev.Lett. 83 (1999) 5596       Phys.Rev.Lett   \n",
       "26867                                                             \n",
       "25469        Nucl.Phys. B416 (1994) 205-226          Nucl.Phys.   \n",
       "12407  Commun.Math.Phys. 209 (2000) 757-783    Commun.Math.Phys   \n",
       "24798    Mod. Phys. Lett. A9 (1994) 557-568      Mod.Phys.Lett.   \n",
       "\n",
       "       Journal-ref-Letters-Paraphrase-KMeans  Journal-ref-Letters-All-KMeans  \n",
       "6846                                       7                               1  \n",
       "3328                                       7                               1  \n",
       "19721                                      7                               1  \n",
       "8793                                       7                               1  \n",
       "19846                                     11                               6  \n",
       "23769                                     11                               6  \n",
       "14039                                     11                               1  \n",
       "3208                                      11                               1  \n",
       "17453                                     11                               6  \n",
       "25780                                     11                               6  \n",
       "27304                                     11                               1  \n",
       "5378                                      11                               6  \n",
       "14325                                     11                               6  \n",
       "111                                       11                               1  \n",
       "10513                                     11                               6  \n",
       "17751                                     11                               1  \n",
       "12610                                     11                               1  \n",
       "13084                                     11                               1  \n",
       "7226                                      11                               6  \n",
       "16908                                     11                               3  \n",
       "1070                                      11                               1  \n",
       "11870                                     11                               1  \n",
       "12100                                     11                               1  \n",
       "9909                                      11                               6  \n",
       "6363                                      11                               6  \n",
       "15848                                     11                               1  \n",
       "26867                                     11                               6  \n",
       "25469                                     11                               1  \n",
       "12407                                     11                               1  \n",
       "24798                                     11                               1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-Letters-Paraphrase-KMeans\", \"Journal-ref-Letters-All-KMeans\"]]\n",
    "    .sample(30)\n",
    "    .sort_values(by=\"Journal-ref-Letters-Paraphrase-KMeans\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b937d-67e5-458f-a8d0-079d941d6159",
   "metadata": {},
   "source": [
    "#### KMeans Did Not Work 2.0\n",
    "\n",
    "Although a nice way to begin, KMeans didn't work.\n",
    "\n",
    "**Q: Do any of you have more experience with KMeans than I do that can make it work to produce good journal clusters? :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ac9ad4a-14b1-4e8c-bb06-309b309f8b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>UMAP()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">UMAP</label><div class=\"sk-toggleable__content\"><pre>UMAP()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "UMAP()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Dimension Reduction with UMAP\n",
    "reducer = umap.UMAP()\n",
    "reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d769fd55-8f03-4f09-a539-c277e2dc0eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  7.109116 ,   6.815907 ],\n",
       "        [  3.1542253,  -7.770678 ],\n",
       "        [ -9.860882 ,  -2.4819782],\n",
       "        ...,\n",
       "        [ -4.8903227,   8.440834 ],\n",
       "        [  2.5886915,  -8.031908 ],\n",
       "        [-17.452026 ,  14.692796 ]], dtype=float32),\n",
       " (27770, 2))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_paraphrase_embeddings = reducer.fit_transform(node_df[\"Journal-ref-Letters-Paraphrase-Embedding\"].tolist())\n",
    "reduced_paraphrase_embeddings, reduced_paraphrase_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f3e2d63b-b61b-4e28-98a1-cb920f01dfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 16.748892 ,   1.5231023],\n",
       "        [  4.056784 ,  12.862727 ],\n",
       "        [-15.029505 ,  11.626479 ],\n",
       "        ...,\n",
       "        [ -2.457551 , -10.922305 ],\n",
       "        [  3.823839 ,  12.549485 ],\n",
       "        [  9.036694 ,  -3.6857252]], dtype=float32),\n",
       " (27770, 2))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_all_embeddings = reducer.fit_transform(node_df[\"Journal-ref-Letters-All-Embedding\"].tolist())\n",
    "reduced_all_embeddings, reduced_all_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105337a3-7a0a-4c2d-a11e-2e5ec61b93a4",
   "metadata": {},
   "source": [
    "#### Clustering with DBSCAN\n",
    "\n",
    "ChatGPT and I say:\n",
    "\n",
    "> DBSCAN groups together closely packed 2-dimensional data points based on a specified distance measure and minimum number of points. It starts with an arbitrary point, expands clusters from suitable points, and identifies noise points that don't belong to any cluster. This makes it good for finding arbitrary shaped clusters and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dca51b0b-2fcb-4aab-b6eb-c8b610b01e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DBSCAN(eps=0.6, min_samples=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DBSCAN</label><div class=\"sk-toggleable__content\"><pre>DBSCAN(eps=0.6, min_samples=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DBSCAN(eps=0.6, min_samples=1000)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Clustering with DBSCAN - you can search for the best hyperparameters\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=1000)#, metric=\"l1\")\n",
    "dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "80dc8a60-a110-45d1-a87a-021dc5137a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_clusters = dbscan.fit_predict(reduced_paraphrase_embeddings)\n",
    "node_df[\"Journal-ref-Letters-Paraphrase-DBSCAN\"] = paraphrase_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19d9d243-8b51-4c6c-aa78-bcd773843a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7]),\n",
       " array([6501, 6994, 3749, 3852, 1285, 1717, 1047, 1070, 1555]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the clusters and their sizes\n",
    "np.unique(paraphrase_clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b9cf21f9-8ea6-41a2-90db-51a5cc5ff9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters = dbscan.fit_predict(reduced_all_embeddings)\n",
    "node_df[\"Journal-ref-Letters-All-DBSCAN\"] = all_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "01088c9b-c7ea-481d-ab01-69c95a11d75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7]),\n",
       " array([6557, 6961, 3755, 3843, 1285, 1719, 1030, 1065, 1555]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the clusters and their sizes\n",
    "np.unique(all_clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7bba40-1f37-40c0-8dde-9387c28ed274",
   "metadata": {},
   "source": [
    "#### Viewing DBSCAN Clusters\n",
    "\n",
    "Let's take a look comparing our two embeddings' clusters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34a2cab6-e936-4716-a3d3-bc3ceb093043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal-ref</th>\n",
       "      <th>Journal-ref-Letters</th>\n",
       "      <th>Journal-ref-Letters-Paraphrase-DBSCAN</th>\n",
       "      <th>Journal-ref-Letters-All-DBSCAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23080</th>\n",
       "      <td>Manila J.Sci. 4 (2001) 17-21</td>\n",
       "      <td>ManilaJ.Sci</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11345</th>\n",
       "      <td>J.Phys. A33 (2000) 3713-3722</td>\n",
       "      <td>J.Phys.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19351</th>\n",
       "      <td>Prog.Theor.Phys. 107 (2002) 805-825</td>\n",
       "      <td>Prog.Theor.Phys</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20389</th>\n",
       "      <td>Phys.Rev.Lett. 89 (2002) 061302</td>\n",
       "      <td>Phys.Rev.Lett</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18689</th>\n",
       "      <td>JHEP 0212 (2002) 058</td>\n",
       "      <td>JHE</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21201</th>\n",
       "      <td>Prog.Theor.Phys. 107 (2002) 1069-1084</td>\n",
       "      <td>Prog.Theor.Phys</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27086</th>\n",
       "      <td>Eur.Phys.J. A2 (1998) 355-370</td>\n",
       "      <td>Eur.Phys.J.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17711</th>\n",
       "      <td>Nucl.Phys.Proc.Suppl. 62 (1998) 161-170</td>\n",
       "      <td>Nucl.Phys.Proc.Suppl</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14405</th>\n",
       "      <td>J.Math.Phys. 35 (1994) 2617-2632</td>\n",
       "      <td>J.Math.Phys</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Phys.Rev.Lett. 75 (1995) 1699-1702</td>\n",
       "      <td>Phys.Rev.Lett</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>Found.Phys. 24 (1994) 1305-1327</td>\n",
       "      <td>Found.Phys</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>J.Geom.Phys. 15 (1995) 189-214</td>\n",
       "      <td>J.Geom.Phys</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>Adv.Math. 113 (1995) 237-303</td>\n",
       "      <td>Adv.Math</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>Eur.Phys.J. C17 (2000) 535-538</td>\n",
       "      <td>Eur.Phys.J.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26616</th>\n",
       "      <td>Annals Phys. 7 (1998) 1-8</td>\n",
       "      <td>AnnalsPhys</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25918</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24677</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27726</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20295</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11418</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23643</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20255</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22686</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22577</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26417</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17461</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>Nucl.Phys. B489 (1997) 487-531</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>Nucl.Phys. B585 (2000) 143-170</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Nucl.Phys. B603 (2001) 497-530</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Nucl.Phys. B416 (1994) 301-334</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19234</th>\n",
       "      <td>Nucl.Phys. B482 (1996) 497-535</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Nucl.Phys. B472 (1996) 683-710</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20657</th>\n",
       "      <td>Nucl.Phys. B423 (1994) 661-687</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>Nucl.Phys. B537 (1999) 361-380</td>\n",
       "      <td>Nucl.Phys.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>Phys.Lett. B322 (1994) 198-206</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13481</th>\n",
       "      <td>Phys.Lett. B493 (2000) 169-174</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>Phys.Lett. B288 (1992) 113-120</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16183</th>\n",
       "      <td>Phys. Lett. B345 (1995) 131-138</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>Phys.Lett. B408 (1997) 142-150</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Phys.Lett. B373 (1996) 76-80</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>Phys.Lett. B296 (1992) 65-70</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Phys.Lett. B302 (1993) 38-46</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>Phys.Lett. B433 (1998) 301-306</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11877</th>\n",
       "      <td>Phys.Lett. B322 (1994) 192-197</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25441</th>\n",
       "      <td>Phys.Lett. B381 (1996) 68-72</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>Phys.Lett. B387 (1996) 294-299</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15901</th>\n",
       "      <td>Phys. Lett. B321 (1994) 219-222</td>\n",
       "      <td>Phys.Lett.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Phys.Rev. D49 (1994) 6857-6863</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Phys.Rev. D60 (1999) 125007</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>Phys.Rev. D61 (2000) 065009</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15141</th>\n",
       "      <td>JHEP 0105 (2001) 013</td>\n",
       "      <td>JHE</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25416</th>\n",
       "      <td>Int. J. Mod. Phys. A11 (1996) 4065</td>\n",
       "      <td>Int.J.Mod.Phys.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>Int.J.Mod.Phys. A15 (2000) 395-411</td>\n",
       "      <td>Int.J.Mod.Phys.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27081</th>\n",
       "      <td>Mod.Phys.Lett. A13 (1998) 2193-2198</td>\n",
       "      <td>Mod.Phys.Lett.</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>Phys.Rev. D53 (1996) 7197-7205</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17321</th>\n",
       "      <td>Phys.Rev. D64 (2001) 106008</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>Phys.Rev. D56 (1997) 4834-4843</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Journal-ref   Journal-ref-Letters  \\\n",
       "23080             Manila J.Sci. 4 (2001) 17-21           ManilaJ.Sci   \n",
       "11345             J.Phys. A33 (2000) 3713-3722               J.Phys.   \n",
       "19351      Prog.Theor.Phys. 107 (2002) 805-825       Prog.Theor.Phys   \n",
       "20389          Phys.Rev.Lett. 89 (2002) 061302         Phys.Rev.Lett   \n",
       "18689                     JHEP 0212 (2002) 058                   JHE   \n",
       "21201    Prog.Theor.Phys. 107 (2002) 1069-1084       Prog.Theor.Phys   \n",
       "27086            Eur.Phys.J. A2 (1998) 355-370           Eur.Phys.J.   \n",
       "17711  Nucl.Phys.Proc.Suppl. 62 (1998) 161-170  Nucl.Phys.Proc.Suppl   \n",
       "14405         J.Math.Phys. 35 (1994) 2617-2632           J.Math.Phys   \n",
       "370         Phys.Rev.Lett. 75 (1995) 1699-1702         Phys.Rev.Lett   \n",
       "11550          Found.Phys. 24 (1994) 1305-1327            Found.Phys   \n",
       "188             J.Geom.Phys. 15 (1995) 189-214           J.Geom.Phys   \n",
       "2577              Adv.Math. 113 (1995) 237-303              Adv.Math   \n",
       "12603           Eur.Phys.J. C17 (2000) 535-538           Eur.Phys.J.   \n",
       "26616                Annals Phys. 7 (1998) 1-8            AnnalsPhys   \n",
       "25918                                                                  \n",
       "24677                                                                  \n",
       "27726                                                                  \n",
       "20295                                                                  \n",
       "11418                                                                  \n",
       "23643                                                                  \n",
       "20255                                                                  \n",
       "6364                                                                   \n",
       "22686                                                                  \n",
       "11106                                                                  \n",
       "22577                                                                  \n",
       "26417                                                                  \n",
       "23702                                                                  \n",
       "17461                                                                  \n",
       "5318            Nucl.Phys. B489 (1997) 487-531            Nucl.Phys.   \n",
       "9373            Nucl.Phys. B585 (2000) 143-170            Nucl.Phys.   \n",
       "14409           Nucl.Phys. B603 (2001) 497-530            Nucl.Phys.   \n",
       "143             Nucl.Phys. B416 (1994) 301-334            Nucl.Phys.   \n",
       "19234           Nucl.Phys. B482 (1996) 497-535            Nucl.Phys.   \n",
       "649             Nucl.Phys. B472 (1996) 683-710            Nucl.Phys.   \n",
       "20657           Nucl.Phys. B423 (1994) 661-687            Nucl.Phys.   \n",
       "2688            Nucl.Phys. B537 (1999) 361-380            Nucl.Phys.   \n",
       "5980            Phys.Lett. B322 (1994) 198-206            Phys.Lett.   \n",
       "13481           Phys.Lett. B493 (2000) 169-174            Phys.Lett.   \n",
       "4547            Phys.Lett. B288 (1992) 113-120            Phys.Lett.   \n",
       "16183          Phys. Lett. B345 (1995) 131-138            Phys.Lett.   \n",
       "4488            Phys.Lett. B408 (1997) 142-150            Phys.Lett.   \n",
       "9995              Phys.Lett. B373 (1996) 76-80            Phys.Lett.   \n",
       "7650              Phys.Lett. B296 (1992) 65-70            Phys.Lett.   \n",
       "117               Phys.Lett. B302 (1993) 38-46            Phys.Lett.   \n",
       "9329            Phys.Lett. B433 (1998) 301-306            Phys.Lett.   \n",
       "11877           Phys.Lett. B322 (1994) 192-197            Phys.Lett.   \n",
       "25441             Phys.Lett. B381 (1996) 68-72            Phys.Lett.   \n",
       "3718            Phys.Lett. B387 (1996) 294-299            Phys.Lett.   \n",
       "15901          Phys. Lett. B321 (1994) 219-222            Phys.Lett.   \n",
       "132             Phys.Rev. D49 (1994) 6857-6863             Phys.Rev.   \n",
       "1652               Phys.Rev. D60 (1999) 125007             Phys.Rev.   \n",
       "6544               Phys.Rev. D61 (2000) 065009             Phys.Rev.   \n",
       "15141                     JHEP 0105 (2001) 013                   JHE   \n",
       "25416       Int. J. Mod. Phys. A11 (1996) 4065       Int.J.Mod.Phys.   \n",
       "6914        Int.J.Mod.Phys. A15 (2000) 395-411       Int.J.Mod.Phys.   \n",
       "27081      Mod.Phys.Lett. A13 (1998) 2193-2198        Mod.Phys.Lett.   \n",
       "8008            Phys.Rev. D53 (1996) 7197-7205             Phys.Rev.   \n",
       "17321              Phys.Rev. D64 (2001) 106008             Phys.Rev.   \n",
       "4337            Phys.Rev. D56 (1997) 4834-4843             Phys.Rev.   \n",
       "\n",
       "       Journal-ref-Letters-Paraphrase-DBSCAN  Journal-ref-Letters-All-DBSCAN  \n",
       "23080                                     -1                              -1  \n",
       "11345                                     -1                              -1  \n",
       "19351                                     -1                              -1  \n",
       "20389                                     -1                              -1  \n",
       "18689                                     -1                              -1  \n",
       "21201                                     -1                              -1  \n",
       "27086                                     -1                              -1  \n",
       "17711                                     -1                              -1  \n",
       "14405                                     -1                              -1  \n",
       "370                                       -1                              -1  \n",
       "11550                                     -1                              -1  \n",
       "188                                       -1                              -1  \n",
       "2577                                      -1                              -1  \n",
       "12603                                     -1                              -1  \n",
       "26616                                     -1                              -1  \n",
       "25918                                      0                               0  \n",
       "24677                                      0                               0  \n",
       "27726                                      0                               0  \n",
       "20295                                      0                               0  \n",
       "11418                                      0                               0  \n",
       "23643                                      0                               0  \n",
       "20255                                      0                               0  \n",
       "6364                                       0                               0  \n",
       "22686                                      0                               0  \n",
       "11106                                      0                               0  \n",
       "22577                                      0                               0  \n",
       "26417                                      0                               0  \n",
       "23702                                      0                               0  \n",
       "17461                                      0                               0  \n",
       "5318                                       1                               1  \n",
       "9373                                       1                               1  \n",
       "14409                                      1                               1  \n",
       "143                                        1                               1  \n",
       "19234                                      1                               1  \n",
       "649                                        1                               1  \n",
       "20657                                      1                               1  \n",
       "2688                                       1                               1  \n",
       "5980                                       2                               2  \n",
       "13481                                      2                               2  \n",
       "4547                                       2                               2  \n",
       "16183                                      2                               2  \n",
       "4488                                       2                               2  \n",
       "9995                                       2                               2  \n",
       "7650                                       2                               2  \n",
       "117                                        2                               2  \n",
       "9329                                       2                               2  \n",
       "11877                                      2                               2  \n",
       "25441                                      2                               2  \n",
       "3718                                       2                               2  \n",
       "15901                                      2                               2  \n",
       "132                                        3                               3  \n",
       "1652                                       3                               3  \n",
       "6544                                       3                               3  \n",
       "15141                                      4                               4  \n",
       "25416                                      5                               5  \n",
       "6914                                       5                               5  \n",
       "27081                                      6                               6  \n",
       "8008                                       7                               7  \n",
       "17321                                      7                               7  \n",
       "4337                                       7                               7  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    node_df[[\n",
    "        \"Journal-ref\",\n",
    "        \"Journal-ref-Letters\",\n",
    "        \"Journal-ref-Letters-Paraphrase-DBSCAN\",\n",
    "        \"Journal-ref-Letters-All-DBSCAN\"\n",
    "    ]]\n",
    "    .sample(60)\n",
    "    \n",
    "    .dropna(axis=0)\n",
    "    .sort_values(by=\"Journal-ref-Letters-All-DBSCAN\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db28a3-a002-48c9-b073-037738379e70",
   "metadata": {},
   "source": [
    "### Nominating Labels for our Clusters\n",
    "\n",
    "Before we even evaluate our clusters by displaying them alongside our `Journal-ref` and `Journal-ref-Letters` in the `node_df` `pd.DataFrame`, I want to perform a trick for labeling clusters using a `GROUP BY`, [MapReduce](https://en.wikipedia.org/wiki/MapReduce) or [split-apply-combine strategy] as you prefer :)\n",
    "\n",
    "We will group by the cluster ID, take [pd.Series.value_counts](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) [a `pd.Series` is a `pd.DataFrame` column] and assign the top value count as the label for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97be23-179f-4283-b858-ee93ad15af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign clusters to the DataFrame\n",
    "node_df[\"Journal-ref-DBSCAN\"] = clusters\n",
    "\n",
    "node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-DBSCAN\"]].groupby(\"Journal-ref-DBSCAN\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35832642-1143-4251-9366-bf3503c08e2b",
   "metadata": {},
   "source": [
    "#### ChatGPT and Me :)\n",
    "\n",
    "I could not get the above code to preview all the clusters... so I enlisted help.\n",
    "\n",
    "Note: this code was written by ChatGPT-4 after 4 attempts. It shows that the `Journal-ref-Count`s are too low to nominate a good name. This led me to allow `.` and ` ` [spaces] in the find/replace above that looked like:\n",
    "\n",
    "```python\n",
    "node_df[\"Journal-ref-Letters\"] = node_df[\"Journal-ref\"].str.replace(r\"[^a-zA-Z]\", \"\", regex=True).str.strip()\n",
    "```\n",
    "\n",
    "The `r\"[^a-zA-Z]\"` now looks like `r\"[^a-zA-Z. ]\"` to include periods and spaces:\n",
    "\n",
    "```python\n",
    "node_df[\"Journal-ref-Letters\"] = node_df[\"Journal-ref\"].str.replace(r\"[^a-zA-Z. ]\", \"\", regex=True).str.strip()\n",
    "```\n",
    "\n",
    "And then things looked good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed603631-3eed-4e1c-b6fc-3ab284dfb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_values(group, n=5):\n",
    "    result = {}\n",
    "    for column in [\"Journal-ref\", \"Journal-ref-Letters\"]:\n",
    "        top_values = group[column].value_counts().nlargest(n)\n",
    "        result[f\"{column}-Value\"] = top_values.index.tolist()\n",
    "        result[f\"{column}-Count\"] = top_values.values.tolist()\n",
    "    return pd.Series(result)\n",
    "\n",
    "# Grouping by 'Journal-ref-DBSCAN' and applying the function\n",
    "top_values_df = node_df.groupby(\"Journal-ref-DBSCAN\").apply(get_top_n_values).reset_index()\n",
    "\n",
    "top_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ebadd-71d5-4129-8ceb-16826377e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df[[\"Journal-ref\", \"Journal-ref-Letters\", \"Journal-ref-DBSCAN\", \"Journal-ref-KMeans\"]].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391cf07-c757-4972-9ce4-100b4cad98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, each point has a cluster label, which could be -1 for noise points\n",
    "# node_df[\"Cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128102e0-1194-45e0-b7fd-3b1b16046b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame(data=reduced_embeddings, columns=['UMAP 1', 'UMAP 2'])\n",
    "plot_data['Cluster ID'] = clusters  # Add cluster labels to the DataFrame\n",
    "\n",
    "# Step 2: Plot the data\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use seaborn's scatterplot function to plot UMAP dimensions,\n",
    "# coloring the points by their cluster ID.\n",
    "# The 'palette' argument specifies the colors to use for each cluster.\n",
    "sns.scatterplot(\n",
    "    x='UMAP 1',  # X-axis: first dimension from UMAP\n",
    "    y='UMAP 2',  # Y-axis: second dimension from UMAP\n",
    "    hue='Cluster ID',  # Color by cluster ID\n",
    "    palette=sns.color_palette(\"hsv\", len(plot_data['Cluster ID'].unique())),  # Use a color palette with enough colors\n",
    "    data=plot_data,  # Data source\n",
    "    legend=\"full\",  # Display a legend\n",
    "    alpha=0.5  # Make points semi-transparent to see overlapping points\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Clusters in 2D UMAP space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d473a3-6978-4692-81e7-d03d3aeea0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from transformers import RobertaTokenizer, RobertaModel\n",
    "# import torch\n",
    "\n",
    "# # Load the tokenizer and model\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# def get_word_embeddings(sentences):\n",
    "#     # Tokenize all sentences in the input array\n",
    "#     inputs = tokenizer(list(sentences), return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "#     # Obtain output embeddings from the model\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "#     # The embeddings of the tokens are contained in the last_hidden_state\n",
    "#     embeddings = outputs.last_hidden_state\n",
    "\n",
    "#     # Convert the tensor to a numpy array\n",
    "#     embeddings = embeddings.detach().numpy()\n",
    "\n",
    "#     return embeddings\n",
    "\n",
    "# # Example usage\n",
    "# sentences = np.array([\"Hello, how are you?\", \"I am fine, thank you! This is a longer sentence.\"])\n",
    "# word_embeddings = get_word_embeddings(sentences)\n",
    "# word_embeddings, word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1aa154-9a17-424f-a14f-8cd109926f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume sentence is a list of words and get_word_embeddings is a function that returns word-level embeddings\n",
    "# sentence = [\"This\", \"is\", \"a\", \"test\", \"sentence\"]\n",
    "# word_embeddings = get_word_embeddings(node_df[\"Journal-ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924fe0a-6624-4650-a042-c7b85d302239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017653cc-c004-4d50-9837-81963ccf95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Design a kernel such that the weight decreases as the position increases\n",
    "# weights = np.linspace(1, 0.1, len(word_embeddings.shape[]))\n",
    "\n",
    "# # Apply the kernel\n",
    "# weighted_embeddings = word_embeddings * weights[:, None]\n",
    "\n",
    "# # Sum the weighted embeddings to get the sentence embedding\n",
    "# roberta_sentence_embedding = np.sum(weighted_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e7a54-75ee-4efc-a117-c72ca39b0435",
   "metadata": {},
   "source": [
    "## Building K-Nearest-Neighbor Networks\n",
    "\n",
    "We are going to use the sentence encoded abstracts in `node_df[\"Abstracts-All-Embedding\"]` to create a KNN Network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee46dd-a0c0-4246-ab89-675494665237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "\n",
    "# Assume df is your DataFrame and 'embedding_column' is the name of the column containing your embeddings\n",
    "df = ...  # your DataFrame\n",
    "\n",
    "# Convert the embedding column to a 2D numpy array\n",
    "embeddings = np.vstack(df['embedding_column'].values)\n",
    "\n",
    "# Step 1: Compute nearest neighbors\n",
    "knn = NearestNeighbors(n_neighbors=6, algorithm='auto')  # n_neighbors=6 because the point itself is included\n",
    "knn.fit(embeddings)\n",
    "distances, indices = knn.kneighbors(embeddings)\n",
    "\n",
    "# Step 2: Create a graph from nearest neighbor relationships\n",
    "G = nx.Graph()\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for neighbor in neighbors[1:]:  # Skip the point itself (neighbors[0] is always the point itself)\n",
    "        G.add_edge(i, neighbor)  # Add an edge between the point and each neighbor\n",
    "\n",
    "# Now G is a graph where each node represents a row in df, and edges connect each node to its k-nearest neighbors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
